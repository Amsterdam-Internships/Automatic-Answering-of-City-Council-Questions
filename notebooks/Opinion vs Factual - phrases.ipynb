{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('questions - questions-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question types\n",
    "- **Factual**\n",
    "- with links \n",
    "- without links\n",
    "\n",
    "\n",
    "- **Opinion-seeking**\n",
    "- with links \n",
    "- without links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ideas:\n",
    "- Unsupervised Learning, where first some words are provided - relevant to each class\n",
    "https://towardsdatascience.com/unsupervised-text-classification-with-lbl2vec-6c5e040354de ;\n",
    "https://github.com/sebischair/Lbl2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequent structures within factual questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog. The lazy dog is not impressed.\"\n",
    "\n",
    "def detect_ngarms_beginning(sentence, n):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    #n = 3 # trigrams\n",
    "    ngrams = list(nltk.ngrams(tokens, n))\n",
    "\n",
    "    beginning_ngrams = []\n",
    "    for gram in ngrams:\n",
    "        if gram[0][0].isupper():\n",
    "            beginning_ngrams.append(gram)\n",
    "    #single_list = [item for sublist in beginning_ngrams for item in sublist]\n",
    "    #freq_dist = nltk.FreqDist(beginning_ngrams)\n",
    "    #top_ngrams = freq_dist.most_common(5)\n",
    "\n",
    "    return beginning_ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ngarms_beginning(sentence,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_all['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = df_all['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ngrams = []\n",
    "q_3grams = []\n",
    "for q in questions: \n",
    "    q_ngrams.append(detect_ngarms_beginning(q, 3))\n",
    "    q_3grams.append(detect_ngarms_beginning(q, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_4grams = []\n",
    "for q in questions: \n",
    "    q_ngrams.append(detect_ngarms_beginning(q, 4))\n",
    "    q_4grams.append(detect_ngarms_beginning(q, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_5grams = []\n",
    "for q in questions: \n",
    "    q_ngrams.append(detect_ngarms_beginning(q, 5))\n",
    "    q_5grams.append(detect_ngarms_beginning(q, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_6grams = []\n",
    "for q in questions: \n",
    "    q_ngrams.append(detect_ngarms_beginning(q, 6))\n",
    "    q_6grams.append(detect_ngarms_beginning(q, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_7grams = []\n",
    "for q in questions: \n",
    "    q_ngrams.append(detect_ngarms_beginning(q, 7))\n",
    "    q_7grams.append(detect_ngarms_beginning(q, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All ngrams - Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_ngrams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "top_ngrams = freq_dist.most_common(45)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_3grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_4grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_5grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_6grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_7grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All ngrams - Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ngrams = []\n",
    "a_3grams = []\n",
    "a_4grams = []\n",
    "a_5grams = []\n",
    "a_6grams = []\n",
    "a_7grams = []\n",
    "\n",
    "for a in answers: \n",
    "    a_ngrams.append(detect_ngarms_beginning(str(a), 3))\n",
    "    a_ngrams.append(detect_ngarms_beginning(str(a), 4))\n",
    "    a_ngrams.append(detect_ngarms_beginning(str(a), 5))\n",
    "    a_ngrams.append(detect_ngarms_beginning(str(a), 6))\n",
    "    a_ngrams.append(detect_ngarms_beginning(str(a), 7))\n",
    "    \n",
    "    a_3grams.append(detect_ngarms_beginning(str(a), 3))\n",
    "    a_4grams.append(detect_ngarms_beginning(str(a), 4))\n",
    "    a_5grams.append(detect_ngarms_beginning(str(a), 5))\n",
    "    a_6grams.append(detect_ngarms_beginning(str(a), 6))\n",
    "    a_7grams.append(detect_ngarms_beginning(str(a), 7))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_ngrams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "top_ngrams = freq_dist.most_common(45)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_3grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_4grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_5grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_6grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in a_7grams for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_links = pd.read_csv('Questions_links_translations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_trans_links['Question']\n",
    "answers = df_trans_links['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ngrams_ = []\n",
    "q_3grams_ = []\n",
    "q_4grams_ = []\n",
    "q_5grams_ = []\n",
    "q_6grams_ = []\n",
    "q_7grams_ = []\n",
    "\n",
    "for q in questions: \n",
    "    q_ngrams_.append(detect_ngarms_beginning(str(q), 3))\n",
    "    q_ngrams_.append(detect_ngarms_beginning(str(q), 4))\n",
    "    q_ngrams_.append(detect_ngarms_beginning(str(q), 5))\n",
    "    q_ngrams_.append(detect_ngarms_beginning(str(q), 6))\n",
    "    q_ngrams_.append(detect_ngarms_beginning(str(q), 7))\n",
    "    \n",
    "    q_3grams_.append(detect_ngarms_beginning(str(q), 3))\n",
    "    q_4grams_.append(detect_ngarms_beginning(str(q), 4))\n",
    "    q_5grams_.append(detect_ngarms_beginning(str(q), 5))\n",
    "    q_6grams_.append(detect_ngarms_beginning(str(q), 6))\n",
    "    q_7grams_.append(detect_ngarms_beginning(str(q), 7))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_ngrams_ for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "top_ngrams = freq_dist.most_common(45)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_4grams_ for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "top_ngrams = freq_dist.most_common(15)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = [item for sublist in q_5grams_ for item in sublist]\n",
    "freq_dist = nltk.FreqDist(single_list)\n",
    "top_ngrams = freq_dist.most_common(15)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
