{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/natalipeeva/Desktop'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data Samples/amsterdam_corpus.pickle', 'rb') as f:\n",
    "    html_contents = pickle.load(f)\n",
    "\n",
    "with open('amsterdam_questions.pickle', \"rb\") as f:\n",
    "     amsterdam_questions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_text(html_content):\n",
    "    \"\"\"\n",
    "    Input: HTML\n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(amsterdam_questions['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(text[0], get_doc_text(text[1]), text[1]) for text in html_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_documents = pd.DataFrame(documents, columns=['URL', 'Text', 'HTML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = supporting_documents['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('supporting_documents.pickle', \"wb\") as f:\n",
    "    pickle.dump(supporting_documents, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process queries and documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('dutch'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stem words\n",
    "    stemmer = nltk.stem.snowball.DutchStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Join words back into a string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_docs = []\n",
    "for doc in documents:\n",
    "    preprocessed_docs.append(preprocess_text(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = preprocessed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_documents['Pre-processed Text'] = preprocessed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_q = []\n",
    "for q in queries:\n",
    "    preprocessed_q.append(preprocess_text(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = preprocessed_q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "document_vectors = vectorizer.fit_transform(documents)\n",
    "query_vectors = vectorizer.transform(queries)\n",
    "\n",
    "# Calculate cosine similarity between each query and document\n",
    "similarity_matrix = cosine_similarity(query_vectors, document_vectors)\n",
    "\n",
    "# Sort documents by cosine similarity score and return top k\n",
    "k = 1\n",
    "top_k_docs = []\n",
    "for i, query in enumerate(queries):\n",
    "    doc_indices = similarity_matrix[i].argsort()[::-1][:k]\n",
    "    #top_k_docs.append((query, [documents[j] for j in doc_indices]))\n",
    "    \n",
    "    top_k_docs.append((query, [documents[j] for j in doc_indices]))\n",
    "    \n",
    "#print(top_k_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = pd.DataFrame()\n",
    "ranking['Question'] = [pair[0] for pair in top_k_docs]\n",
    "ranking['Rank1'] = [pair[1][0] for pair in top_k_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Rank1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huisarts gev informatie nodig declaratiemog ge...</td>\n",
       "      <td>windmolen amsterdam gemeent amsterdam direct i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wet ongedocumenteerd weg medisch instell zoal ...</td>\n",
       "      <td>ongedocumenteerd gemeent amsterdam gemeenteams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spug speciaal daartoe getraind opsporingsambte...</td>\n",
       "      <td>mag buitengewon opsporingsambtenar boa handhav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gat wethouder ontslag zorg voorkom enkel noodzak</td>\n",
       "      <td>hulp zorg betal gemeent amsterdam gemeenteamst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reactie rapport schrijft colleg klopt all sign...</td>\n",
       "      <td>melding open ruimt overlast gemeent amsterdam ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  huisarts gev informatie nodig declaratiemog ge...   \n",
       "1  wet ongedocumenteerd weg medisch instell zoal ...   \n",
       "2  spug speciaal daartoe getraind opsporingsambte...   \n",
       "3   gat wethouder ontslag zorg voorkom enkel noodzak   \n",
       "4  reactie rapport schrijft colleg klopt all sign...   \n",
       "\n",
       "                                               Rank1  \n",
       "0  windmolen amsterdam gemeent amsterdam direct i...  \n",
       "1  ongedocumenteerd gemeent amsterdam gemeenteams...  \n",
       "2  mag buitengewon opsporingsambtenar boa handhav...  \n",
       "3  hulp zorg betal gemeent amsterdam gemeenteamst...  \n",
       "4  melding open ruimt overlast gemeent amsterdam ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(ranking, supporting_documents, left_on='Rank1', right_on='Pre-processed Text', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df= merged_df.drop_duplicates(subset='Question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Rank1</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Pre-processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huisarts gev informatie nodig declaratiemog ge...</td>\n",
       "      <td>windmolen amsterdam gemeent amsterdam direct i...</td>\n",
       "      <td>/onderwepen/amsterdam-wonen-leefomgeving/www.a...</td>\n",
       "      <td>\\n\\n\\n\\nWindmolens in Amsterdam - Gemeente Ams...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=nl&gt;\\n&lt;head prefix=...</td>\n",
       "      <td>windmolen amsterdam gemeent amsterdam direct i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wet ongedocumenteerd weg medisch instell zoal ...</td>\n",
       "      <td>ongedocumenteerd gemeent amsterdam gemeenteams...</td>\n",
       "      <td>/onderwepen/amsterdam-wonen-leefomgeving/www.a...</td>\n",
       "      <td>\\n\\n\\n\\nOngedocumenteerden - Gemeente Amsterda...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=nl&gt;\\n&lt;head prefix=...</td>\n",
       "      <td>ongedocumenteerd gemeent amsterdam gemeenteams...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  huisarts gev informatie nodig declaratiemog ge...   \n",
       "2  wet ongedocumenteerd weg medisch instell zoal ...   \n",
       "\n",
       "                                               Rank1  \\\n",
       "0  windmolen amsterdam gemeent amsterdam direct i...   \n",
       "2  ongedocumenteerd gemeent amsterdam gemeenteams...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  /onderwepen/amsterdam-wonen-leefomgeving/www.a...   \n",
       "2  /onderwepen/amsterdam-wonen-leefomgeving/www.a...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  \\n\\n\\n\\nWindmolens in Amsterdam - Gemeente Ams...   \n",
       "2  \\n\\n\\n\\nOngedocumenteerden - Gemeente Amsterda...   \n",
       "\n",
       "                                                HTML  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=nl>\\n<head prefix=...   \n",
       "2  <!DOCTYPE html>\\n<html lang=nl>\\n<head prefix=...   \n",
       "\n",
       "                                  Pre-processed Text  \n",
       "0  windmolen amsterdam gemeent amsterdam direct i...  \n",
       "2  ongedocumenteerd gemeent amsterdam gemeenteams...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_path(link, start):\n",
    "    \"\"\"\n",
    "    Where start is the domain name; e.g. 'www.amsterdam.nl/'\n",
    "    \"\"\"\n",
    "    # start = 'www.amsterdam.nl/'\n",
    "    end = '/'\n",
    "\n",
    "    start_index = link.index(start) + len(start)\n",
    "    end_index = link.index(end, start_index)\n",
    "\n",
    "    result = link[start_index:end_index]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_paths = []\n",
    "for link in merged_df['URL']:\n",
    "    try: \n",
    "        url_paths.append((link, extract_path(link, 'www.amsterdam.nl/')))\n",
    "    except:\n",
    "        try: \n",
    "            url_paths.append((link, link.split('http://www.amsterdam.nl/')[1]))\n",
    "        except:\n",
    "            url_paths.append((link, link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_paths = [path[1] for path in url_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonen-leefomgeving', 'zorg-ondersteuning', 'veelgevraagd']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(amsterdam_questions['URL_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for i in range(len(paths)):\n",
    "    if paths[i] == predicted_paths[i]:\n",
    "        matches.append(1)\n",
    "    else:\n",
    "        matches.append(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
