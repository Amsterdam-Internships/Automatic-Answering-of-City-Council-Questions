{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions\n"
     ]
    }
   ],
   "source": [
    "%cd  /Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "from hashids import Hashids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking = pd.read_csv('data/question_answer/amsterdam_questions.csv')\n",
    "collection = pd.read_csv('data/amsterdam/amsterdam_full.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data to Paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passages function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_passages_dataframe(collection):\n",
    "    all_passages_df = pd.DataFrame(columns=['URL', 'Textual_Content'])\n",
    "\n",
    "    for index, row in collection.iterrows():\n",
    "        url = row['URL']\n",
    "        content = str(row['Textual_Content'])\n",
    "\n",
    "        sentences = nltk.sent_tokenize(content, language='dutch')\n",
    "\n",
    "        passages = []\n",
    "        passage_words = []\n",
    "        word_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_words = nltk.word_tokenize(sentence, language='dutch')\n",
    "\n",
    "            while len(sentence_words) > 0:\n",
    "                if word_count + len(sentence_words) <= 100:\n",
    "                    passage_words.extend(sentence_words)\n",
    "                    word_count += len(sentence_words)\n",
    "                    sentence_words = []\n",
    "                else:\n",
    "                    remaining_words = 100 - word_count\n",
    "                    passage_words.extend(sentence_words[:remaining_words])\n",
    "                    passages.append(' '.join(passage_words))\n",
    "                    passage_words = []\n",
    "                    word_count = 0\n",
    "                    sentence_words = sentence_words[remaining_words:]\n",
    "\n",
    "        if passage_words:\n",
    "            passages.append(' '.join(passage_words))\n",
    "\n",
    "        passage_df = pd.DataFrame({'URL': url, 'Textual_Content': passages})\n",
    "        all_passages_df = pd.concat([all_passages_df, passage_df], ignore_index=True)\n",
    "\n",
    "    return all_passages_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df = create_passages_dataframe(collection) # 50 secs for execution\n",
    "len(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add passage ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "passages_df[\"id\"] = [hashids.encode(i) for i in range(len(passages_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Textual_Content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60897</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>evenementen . Lijst Over deze site Privacy Coo...</td>\n",
       "      <td>r1vk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60898</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>Hulp voor dak- of thuislozen - Gemeente Amster...</td>\n",
       "      <td>v1zg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60899</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>Op zoek naar ( tijdelijke ) woonruimte Opvang ...</td>\n",
       "      <td>w1Am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60900</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>onverzekerden Collectieve zorgverzekering Amst...</td>\n",
       "      <td>g0GZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60901</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>tot inspraakavonden . Wat organiseert de gemee...</td>\n",
       "      <td>j1kY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URL  \\\n",
       "60897  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "60898  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60899  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60900  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60901  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "\n",
       "                                         Textual_Content    id  \n",
       "60897  evenementen . Lijst Over deze site Privacy Coo...  r1vk  \n",
       "60898  Hulp voor dak- of thuislozen - Gemeente Amster...  v1zg  \n",
       "60899  Op zoek naar ( tijdelijke ) woonruimte Opvang ...  w1Am  \n",
       "60900  onverzekerden Collectieve zorgverzekering Amst...  g0GZ  \n",
       "60901  tot inspraakavonden . Wat organiseert de gemee...  j1kY  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add paragraphs ids to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_passages_ids(questions_for_ranking, passages_df):\n",
    "    matching_ids_column = []\n",
    "    for index, row in questions_for_ranking.iterrows():\n",
    "        matching_ids = []\n",
    "        for url in ast.literal_eval(row['URLs']):\n",
    "            for index2, row2 in passages_df.iterrows():\n",
    "                if url == row2['URL']:\n",
    "                    matching_ids.append(row2['id'])\n",
    "        if matching_ids:\n",
    "            matching_ids_column.append(matching_ids)\n",
    "        else:\n",
    "            matching_ids_column.append(None)\n",
    "    questions_for_ranking['passages_ids'] = matching_ids_column\n",
    "    return questions_for_ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking = add_passages_ids(questions_for_ranking, passages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Cleaned_URLs</th>\n",
       "      <th>passages_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>\\n7.\\nKan het college de reeds bestaande zwemp...</td>\n",
       "      <td>\\nVoor het vinden van de officiële zwemplekken...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?casei...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?casei...</td>\n",
       "      <td>[y8RV, zm0r, AnyB, Bgzx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n3. Huisartsen geven aan meer informatie n...</td>\n",
       "      <td>\\nDe uitvoerder van de regeling, het CAK, lij...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n8. Weten ongedocumenteerden de weg naar m...</td>\n",
       "      <td>\\nDe Kruispost wordt goed bezocht, maar het c...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>\\n \\n4. Is het college tot nu toe tevreden met...</td>\n",
       "      <td>\\nJa, met de beschikbare middelen is de uitvo...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/wonen-leefomgeving/...</td>\n",
       "      <td>['https://www.amsterdam.nl/wonen-leefomgeving/...</td>\n",
       "      <td>[zkqm, Ap8P, Bq1N, Dvwq, EwK0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>\\n \\n1. \\nKan aan de werkinstructie worden toe...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/privacy/loket/']</td>\n",
       "      <td>['https://www.amsterdam.nl/privacy/loket/']</td>\n",
       "      <td>[G0w8, JBEP, KDAY, LEAA]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  Year  Month  \\\n",
       "0             1           1  2020      6   \n",
       "1             6           7  2021      8   \n",
       "2             7           8  2021      8   \n",
       "3             9          14  2022      7   \n",
       "4            10          16  2019     10   \n",
       "\n",
       "                                            Question  \\\n",
       "0  \\n7.\\nKan het college de reeds bestaande zwemp...   \n",
       "1  \\n \\n3. Huisartsen geven aan meer informatie n...   \n",
       "2  \\n \\n8. Weten ongedocumenteerden de weg naar m...   \n",
       "3  \\n \\n4. Is het college tot nu toe tevreden met...   \n",
       "4  \\n \\n1. \\nKan aan de werkinstructie worden toe...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  \\nVoor het vinden van de officiële zwemplekken...   \n",
       "1   \\nDe uitvoerder van de regeling, het CAK, lij...   \n",
       "2   \\nDe Kruispost wordt goed bezocht, maar het c...   \n",
       "3   \\nJa, met de beschikbare middelen is de uitvo...   \n",
       "4                                                ...   \n",
       "\n",
       "                                            Document  \\\n",
       "0  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "1  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "2  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "3  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "4  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "\n",
       "                                                URLs  \\\n",
       "0  ['https://www.amsterdam.nl/veelgevraagd/?casei...   \n",
       "1  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "2  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "3  ['https://www.amsterdam.nl/wonen-leefomgeving/...   \n",
       "4        ['https://www.amsterdam.nl/privacy/loket/']   \n",
       "\n",
       "                                        Cleaned_URLs  \\\n",
       "0  ['https://www.amsterdam.nl/veelgevraagd/?casei...   \n",
       "1  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "2  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "3  ['https://www.amsterdam.nl/wonen-leefomgeving/...   \n",
       "4        ['https://www.amsterdam.nl/privacy/loket/']   \n",
       "\n",
       "                                        passages_ids  \n",
       "0                           [y8RV, zm0r, AnyB, Bgzx]  \n",
       "1  [nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...  \n",
       "2  [nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...  \n",
       "3                     [zkqm, Ap8P, Bq1N, Dvwq, EwK0]  \n",
       "4                           [G0w8, JBEP, KDAY, LEAA]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add question ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "questions_for_ranking[\"question_id\"] = [hashids.encode(i) for i in range(len(questions_for_ranking))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Cleaned_URLs</th>\n",
       "      <th>passages_ids</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>124</td>\n",
       "      <td>178</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n2. Hoe evalueert het college het function...</td>\n",
       "      <td>\\nOp  22 september 2009 stemde het toenmalige...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?produ...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?produ...</td>\n",
       "      <td>[wjXR, g5A6, j2E5, k5GX, lOJ6, mwK0, nZLl, oYM...</td>\n",
       "      <td>Nk6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>127</td>\n",
       "      <td>181</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>\\n3. Is het college bereid om te investeren in...</td>\n",
       "      <td>\\nHet college investeert al in de signalerend...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/sociaaldomein/zorgp...</td>\n",
       "      <td>['https://www.amsterdam.nl/sociaaldomein/zorgp...</td>\n",
       "      <td>[0KpG, g0Kl, j1Mz, k1KY, l1LJ, m56A, n1XD]</td>\n",
       "      <td>OYp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>128</td>\n",
       "      <td>182</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>\\n \\n2. Deelt het college de mening dat het ee...</td>\n",
       "      <td>\\nNee, het college deelt deze mening van de P...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/nrga/']</td>\n",
       "      <td>['https://www.amsterdam.nl/nrga/']</td>\n",
       "      <td>[o1KN, p1Kr, q1XR, r1Nk, v17g, w18m, xgNn, yjO...</td>\n",
       "      <td>PNw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>129</td>\n",
       "      <td>183</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n \\n \\n6.  Recent heeft de burgemeester aange...</td>\n",
       "      <td>\\na) Het verlenen van een vergunning is een b...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/nieuws/kennisgeving...</td>\n",
       "      <td>['https://www.amsterdam.nl/nieuws/kennisgeving...</td>\n",
       "      <td>[j1Vz, k1VY, l1VJ, m5VA, n1VD, o19N, p16r, q1r...</td>\n",
       "      <td>QWl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>134</td>\n",
       "      <td>193</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n \\n12. Welke informatievoorziening is er van...</td>\n",
       "      <td>\\nZorgaanbieders zijn verantwoordelijk voor h...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[n1GE, o1A3, p19N, q1AG, v1zg, w1Am, g0GZ, j1kY]</td>\n",
       "      <td>R6q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  Year  Month  \\\n",
       "68           124         178  2014      8   \n",
       "69           127         181  2022      5   \n",
       "70           128         182  2017      5   \n",
       "71           129         183  2020      2   \n",
       "72           134         193  2020      3   \n",
       "\n",
       "                                             Question  \\\n",
       "68  \\n \\n2. Hoe evalueert het college het function...   \n",
       "69  \\n3. Is het college bereid om te investeren in...   \n",
       "70  \\n \\n2. Deelt het college de mening dat het ee...   \n",
       "71  \\n \\n \\n6.  Recent heeft de burgemeester aange...   \n",
       "72  \\n \\n12. Welke informatievoorziening is er van...   \n",
       "\n",
       "                                               Answer  \\\n",
       "68   \\nOp  22 september 2009 stemde het toenmalige...   \n",
       "69   \\nHet college investeert al in de signalerend...   \n",
       "70   \\nNee, het college deelt deze mening van de P...   \n",
       "71   \\na) Het verlenen van een vergunning is een b...   \n",
       "72   \\nZorgaanbieders zijn verantwoordelijk voor h...   \n",
       "\n",
       "                                             Document  \\\n",
       "68  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "69  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "70  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "71  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "72  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "\n",
       "                                                 URLs  \\\n",
       "68  ['https://www.amsterdam.nl/veelgevraagd/?produ...   \n",
       "69  ['https://www.amsterdam.nl/sociaaldomein/zorgp...   \n",
       "70                 ['https://www.amsterdam.nl/nrga/']   \n",
       "71  ['https://www.amsterdam.nl/nieuws/kennisgeving...   \n",
       "72  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "\n",
       "                                         Cleaned_URLs  \\\n",
       "68  ['https://www.amsterdam.nl/veelgevraagd/?produ...   \n",
       "69  ['https://www.amsterdam.nl/sociaaldomein/zorgp...   \n",
       "70                 ['https://www.amsterdam.nl/nrga/']   \n",
       "71  ['https://www.amsterdam.nl/nieuws/kennisgeving...   \n",
       "72  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "\n",
       "                                         passages_ids question_id  \n",
       "68  [wjXR, g5A6, j2E5, k5GX, lOJ6, mwK0, nZLl, oYM...         Nk6  \n",
       "69         [0KpG, g0Kl, j1Mz, k1KY, l1LJ, m56A, n1XD]         OYp  \n",
       "70  [o1KN, p1Kr, q1XR, r1Nk, v17g, w18m, xgNn, yjO...         PNw  \n",
       "71  [j1Vz, k1VY, l1VJ, m5VA, n1VD, o19N, p16r, q1r...         QWl  \n",
       "72   [n1GE, o1A3, p19N, q1AG, v1zg, w1Am, g0GZ, j1kY]         R6q  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Cleaned_URLs', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(questions_for_ranking)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "questions_for_ranking = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2020,\n",
       " 'Month': 6,\n",
       " 'Question': '\\n7.\\nKan het college de reeds bestaande zwemplekken in Amsterdam en de directe \\nomgeving, die zich op fietsafstand bevinden, beter communiceren zodat mensen \\nweten waar ze allemaal heen kunnen op de fiets om te zwemmen?\\n',\n",
       " 'Answer': '\\nVoor het vinden van de officiële zwemplekken is er informatie op de site \\nhttps://www.zwemwater.nl/.Hier is ook informatie te vinden over veilig zwemmen en gezondheidsrisico’s en het \\nCorona protocol zwemmen en recreëren in en aan oppervlaktewater.\\nOp de kaart met zwemwater, stadsstranden en fonteinen geeft de gemeente \\nAmsterdam een overzicht van zwemplekken in open water: \\nhttps://maps.amsterdam.nl/zwemwater/ . \\nZie tevens de site: https://www.amsterdam.nl/veelgevraagd/?caseid=%7BD6E280FB-\\n4A76-40A0-9B88-12B87E446FA6%7D\\nVoorts is het voor de gezondheidsrisico’s goed kennis te nemen van de site van de \\nGGD over het zwemmen in open water: https://www.ggd.amsterdam.nl/gezond-\\nwonen/zwemmen-open-water/ ',\n",
       " 'Document': 'https://amsterdam.raadsinformatie.nl/document/8824200/5/888',\n",
       " 'URLs': \"['https://www.amsterdam.nl/veelgevraagd/?caseid=%7BD6E280FB-4A76-40A0-9B88-12B87E446FA6%7D', 'https://www.ggd.amsterdam.nl/gezond-wonen/zwemmen-open-water/']\",\n",
       " 'passages_ids': ['y8RV', 'zm0r', 'AnyB', 'Bgzx'],\n",
       " 'question_id': 'gY'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(passages_df)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "passages_df = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URL': 'https://www.amsterdam.nl/veelgevraagd/meer-veel-gezochte-vragen/?view=top&categoryid=%7B11ADEA27-898E-482C-97D4-48CFCEFE550C%7D',\n",
       " 'Textual_Content': 'Wat mag er in de broodcontainer ? Wat mag er bij het blad- en snoeiafval ? Deel deze pagina Deel deze pagina op Facebook Deel deze pagina op Twitter Deel deze pagina op LinkedIn Deel deze pagina op WhatsApp Print deze pagina Gemeente Amsterdam Contact Hebt u een vraag en kunt u het antwoord niet vinden op deze website ? Neem dan contact met ons op . Contactformulier Bel het telefoonnummer 14 020maandag tot en met vrijdag van 08.00 tot 18.00 uur Contactgegevens en openingstijden Volg de gemeente Nieuwsbrief Amsterdam Twitter Facebook Instagram LinkedIn YouTube Werkenbij Kalender Van buurtactiviteiten tot',\n",
       " 'id': 'gN3'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Amsterdam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_search(query, vectorizer, matrix, collection, k):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using tf-idf.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        vectorizer: a fitted TfidfVectorizer\n",
    "        matrix: the document-term matrix obtained from the fitted vectorizer\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of (document_id, score, document_content), sorted in descending relevance to the given query\n",
    "    \"\"\"\n",
    "    # preprocess the query # could preprocess more?\n",
    "    preprocessed_query = str(query['Question']).lower().replace('\\n', '')\n",
    "\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "\n",
    "    query_vector = vectorizer.transform([preprocessed_query])\n",
    "    question_id = query['question_id']\n",
    "\n",
    "    cosine_similarities = matrix.dot(query_vector.T).toarray().flatten()\n",
    "\n",
    "    results_heap = []  # heap for efficiency to maintain the top-k results\n",
    "\n",
    "    # iterate over the collection and update the heap with the top-k results\n",
    "    for i, doc in enumerate(collection):\n",
    "        doc_id = doc['id']\n",
    "        score = cosine_similarities[i]\n",
    "        document_content = doc['Textual_Content']\n",
    "        heapq.heappush(results_heap, (score, doc_id, document_content))\n",
    "        if len(results_heap) > k:\n",
    "            heapq.heappop(results_heap)\n",
    "\n",
    "    results_heap.sort(reverse=True)  # sort descending\n",
    "    top_results = results_heap[:k]\n",
    "\n",
    "    cosine_scores = [result[0] for result in top_results]\n",
    "    ranked_ids = [result[1] for result in top_results]\n",
    "    ranked_text = [result[2] for result in top_results]\n",
    "\n",
    "    # create a dictionary containing the search results\n",
    "    search_results = {\n",
    "        'question_id': question_id,\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'cosine_scores': cosine_scores, \n",
    "        'answer': query['Answer']\n",
    "    }\n",
    "\n",
    "    return search_results  # return top k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tfidf_search(queries, collection, k):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a dictionary where the key is the query and the value is a list of (document_id, score, document_content) tuples\n",
    "    \"\"\"\n",
    "    # extract document contents from the collection\n",
    "    document_contents = [str(doc['Textual_Content']).lower().replace('\\n', '') for doc in collection]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(document_contents)\n",
    "\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = tfidf_search(query, vectorizer, matrix, collection, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = perform_tfidf_search(questions_for_ranking, passages_df, k=100) # 2:18 mins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.topk import recall, ap, ndcg, precision, rr, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.relevance import relevant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant_counts(relevant[:, np.newaxis], ranked[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics(results, k):\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "    rr_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for result in results:\n",
    "        ranked = result['ranked_ids']\n",
    "        relevant = result['true_passages']\n",
    "\n",
    "        recall_k = recall(relevant, ranked, k)\n",
    "        ndcg_k = calculate_ndcg(relevant, ranked, k)\n",
    "        rr_k = rr(relevant, ranked, k)\n",
    "        precision_k = precision(relevant, ranked, k)\n",
    "\n",
    "        recall_scores.append(recall_k)\n",
    "        ndcg_scores.append(ndcg_k)\n",
    "        rr_scores.append(rr_k)\n",
    "        precision_scores.append(precision_k)\n",
    "\n",
    "    average_recall = sum(recall_scores) / len(recall_scores)\n",
    "    average_ndcg = sum(ndcg_scores) / len(ndcg_scores)\n",
    "    average_rr = sum(rr_scores) / len(rr_scores)\n",
    "    average_precision = sum(precision_scores) / len(precision_scores)\n",
    "\n",
    "    average_metrics = {\n",
    "        'average_recall@{}'.format(k): average_recall,\n",
    "        'average_ndcg@{}'.format(k): average_ndcg,\n",
    "        'average_rr@{}'.format(k): average_rr,\n",
    "        'average_precision@{}'.format(k): average_precision\n",
    "    }\n",
    "\n",
    "    return average_metrics\n",
    "\n",
    "\n",
    "def calculate_ndcg(relevant, ranked, k):\n",
    "    warnings.filterwarnings('ignore', 'invalid value encountered', RuntimeWarning)\n",
    "    ndcg_k = ndcg(relevant, ranked, k)\n",
    "    if np.isnan(ndcg_k) or np.isinf(ndcg_k):\n",
    "        ndcg_k = 0.0\n",
    "    return ndcg_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0274\n",
      "average_ndcg@5: 0.0539\n",
      "average_rr@5: 0.0422\n",
      "average_precision@5: 0.0274\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0192\n",
      "average_ndcg@10: 0.0577\n",
      "average_rr@10: 0.0491\n",
      "average_precision@10: 0.0164\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0758\n",
      "average_ndcg@100: 0.1008\n",
      "average_rr@100: 0.0585\n",
      "average_precision@100: 0.0078\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_tfidf.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_search(query, collection, k):\n",
    "    \"\"\"\n",
    "    Perform random retrieval from the collection.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a dictionary containing the search results\n",
    "    \"\"\"\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "\n",
    "    # Randomly select k documents from the collection\n",
    "    random_results = random.sample(collection.to_list(), k)\n",
    "\n",
    "    ranked_ids = [result['id'] for result in random_results]\n",
    "    ranked_text = [result['Textual_Content'] for result in random_results]\n",
    "    cosine_scores = []  # Assign random scores for demonstration purposes\n",
    "\n",
    "    # Create a dictionary containing the search results\n",
    "    search_results = {\n",
    "        'question_id': query['question_id'],\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'cosine_scores': cosine_scores,\n",
    "        'answer': query['Answer'],\n",
    "    }\n",
    "\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_random_search(queries, collection, k):\n",
    "    \"\"\"\n",
    "    Perform random retrieval search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        collection: a pandas DataFrame representing the collection\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of dictionaries containing the search results\n",
    "    \"\"\"\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = random_search(query, collection, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random = perform_random_search(questions_for_ranking, passages_df, k=100) # 18 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0000\n",
      "average_ndcg@5: 0.0000\n",
      "average_rr@5: 0.0000\n",
      "average_precision@5: 0.0000\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0000\n",
      "average_ndcg@10: 0.0000\n",
      "average_rr@10: 0.0000\n",
      "average_precision@10: 0.0000\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0000\n",
      "average_ndcg@100: 0.0000\n",
      "average_rr@100: 0.0000\n",
      "average_precision@100: 0.0000\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results_random, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from rank_bm25 import BM25L\n",
    "from rank_bm25 import BM25Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, corpus, bm25, k):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using BM25 ranking.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        collection: a list of document contents\n",
    "        bm25: initialized BM25Okapi object\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of (document_id, score, document_content), sorted in descending relevance to the given query\n",
    "    \"\"\"\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = str(query['Question']).lower().replace('\\n', '')\n",
    "    query_tokens = preprocessed_query.split()\n",
    "\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    results_heap = []\n",
    "\n",
    "    # Iterate over the corpus and update the heap with the top-k results\n",
    "    for i, doc in enumerate(corpus):\n",
    "        doc_id = doc['id']\n",
    "        score = scores[i]\n",
    "        document_content = doc['Textual_Content']\n",
    "        heapq.heappush(results_heap, (score, doc_id, document_content))\n",
    "        if len(results_heap) > k:\n",
    "            heapq.heappop(results_heap)\n",
    "\n",
    "    results_heap.sort(reverse=True)  # Sort descending\n",
    "    top_results = results_heap[:k]\n",
    "\n",
    "    bm25_scores = [result[0] for result in top_results]\n",
    "    ranked_ids = [result[1] for result in top_results]\n",
    "    ranked_text = [result[2] for result in top_results]\n",
    "\n",
    "    # Create a dictionary containing the search results\n",
    "\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "    question_id = query['question_id']\n",
    "\n",
    "    search_results = {\n",
    "    'question_id': question_id,\n",
    "    'question': query_text,\n",
    "    'ranked_ids': ranked_ids,\n",
    "    'ranked_text': ranked_text,\n",
    "    'true_passages': true_documents,\n",
    "    'scores': bm25_scores, \n",
    "    'answer': query['Answer']\n",
    "    }\n",
    "\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_bm25_search(queries, corpus, k):\n",
    "    \"\"\"\n",
    "    Perform BM25 search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        corpus: a list of document contents\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of dictionaries, where each dictionary contains the search results for a query\n",
    "    \"\"\"\n",
    "    # Preprocess the corpus\n",
    "    tokenized_corpus = [doc['Textual_Content'].lower().replace('\\n', '').split() for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = bm25_search(query, corpus, bm25, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bm25 = perform_bm25_search(questions_for_ranking, passages_df, k=100) # 3:22 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for p in passages_df:\n",
    "    counter.append(len(p['Textual_Content'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(counter)\n",
    "max_indices = [index for index, value in enumerate(counter) if value == max_value]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0027\n",
      "average_ndcg@5: 0.0086\n",
      "average_rr@5: 0.0068\n",
      "average_precision@5: 0.0027\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0027\n",
      "average_ndcg@10: 0.0083\n",
      "average_rr@10: 0.0068\n",
      "average_precision@10: 0.0027\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0211\n",
      "average_ndcg@100: 0.0347\n",
      "average_rr@100: 0.0106\n",
      "average_precision@100: 0.0029\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results_bm25, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value)) #BM25 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_bm25.pickle', 'wb') as f:\n",
    "    pickle.dump(results_bm25, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_random.pickle', 'wb') as f:\n",
    "    pickle.dump(results_random, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the language to Dutch\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_len = []\n",
    "for q in questions_for_ranking:\n",
    "    ans_len.append(len(word_tokenize(q['Answer'], language='dutch')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.8767123287671"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ans_len)/len(ans_len) # 256.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(generated_summaries, reference_summaries):\n",
    "    # Convert non-string elements to strings\n",
    "    generated_summaries = [str(summary) for summary in generated_summaries]\n",
    "    reference_summaries = [str(summary) for summary in reference_summaries]\n",
    "\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    rouge_scores = []\n",
    "    for generated_summary, reference_summary in zip(generated_summaries, reference_summaries):\n",
    "        scores = scorer.score(generated_summary, reference_summary)\n",
    "        rouge_scores.append(scores)\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_score = corpus_bleu([[ref.split()] for ref in reference_summaries], [gen.split() for gen in generated_summaries], smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(reference_summaries, generated_summaries, average='micro')  # Adjust 'average' parameter as needed\n",
    "\n",
    "\n",
    "    # Access the scores as needed\n",
    "    metrics = {\n",
    "        \"ROUGE-1 (Average)\": sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"ROUGE-2 (Average)\": sum([score['rouge2'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"ROUGE-L (Average)\": sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"BLEU Score\": bleu_score,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_answer(list_passages):\n",
    "    concatenated_string = \"\"  # Initialize the concatenated string\n",
    "    for paragraph in list_passages:\n",
    "        tokens = word_tokenize(paragraph)\n",
    "        if len(word_tokenize(concatenated_string)) + len(tokens) <= 256:\n",
    "            concatenated_string += \" \" + paragraph\n",
    "        else:\n",
    "            break  # Stop concatenating if the token count exceeds 256\n",
    "    return concatenated_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers = []\n",
    "for result in results:\n",
    "    simulated_answers.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for question in questions_for_ranking:\n",
    "    answers.append(question['Answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.2313289582763451,\n",
       " 'ROUGE-2 (Average)': 0.0344184919464686,\n",
       " 'ROUGE-L (Average)': 0.12278253414413527,\n",
       " 'BLEU Score': 0.007980492756711336,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers_random = []\n",
    "for result in results_random:\n",
    "    simulated_answers_random.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.19952015091584155,\n",
       " 'ROUGE-2 (Average)': 0.02156878779122388,\n",
       " 'ROUGE-L (Average)': 0.1092907814352237,\n",
       " 'BLEU Score': 0.0032005437617806634,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers_random, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers_bm25 = []\n",
    "for result in results_bm25:\n",
    "    simulated_answers_bm25.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.2538702529604056,\n",
       " 'ROUGE-2 (Average)': 0.03811834858547292,\n",
       " 'ROUGE-L (Average)': 0.1352721216338226,\n",
       " 'BLEU Score': 0.00818301351999974,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers_bm25, answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking all with best ranker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get BM25 for all questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('data/question_answer/questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "questions[\"question_id\"] = [hashids.encode(i) for i in range(len(questions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n1. Heeft het college kennisgenomen van de...</td>\n",
       "      <td>\\nNee.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n2. Kan het college bevestigen of dit lesm...</td>\n",
       "      <td>\\nNee, het college heeft hier geen zicht op. ...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n                                         ...</td>\n",
       "      <td>\\nHet CIDI is duidelijk over de eigen doelste...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n4. Is het college bekend met de jaarlijks...</td>\n",
       "      <td>\\nHet college heeft hier kennis van genomen.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\na. Is het college van oordeel dat het CID...</td>\n",
       "      <td>vraag 4a: \\nHet college is voor een pluriform...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month                                           Question  \\\n",
       "0  2018    12  \\n \\n1. Heeft het college kennisgenomen van de...   \n",
       "1  2018    12  \\n \\n2. Kan het college bevestigen of dit lesm...   \n",
       "2  2018    12  \\n \\n                                         ...   \n",
       "3  2018    12  \\n \\n4. Is het college bekend met de jaarlijks...   \n",
       "4  2018    12  \\n \\na. Is het college van oordeel dat het CID...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0                                           \\nNee.     \n",
       "1   \\nNee, het college heeft hier geen zicht op. ...   \n",
       "2   \\nHet CIDI is duidelijk over de eigen doelste...   \n",
       "3      \\nHet college heeft hier kennis van genomen.    \n",
       "4   vraag 4a: \\nHet college is voor een pluriform...   \n",
       "\n",
       "                                            Document URLs question_id  \n",
       "0  https://amsterdam.raadsinformatie.nl/document/...  NaN          gY  \n",
       "1  https://amsterdam.raadsinformatie.nl/document/...  NaN          jR  \n",
       "2  https://amsterdam.raadsinformatie.nl/document/...  NaN          k5  \n",
       "3  https://amsterdam.raadsinformatie.nl/document/...  NaN          l5  \n",
       "4  https://amsterdam.raadsinformatie.nl/document/...  NaN          mO  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(questions)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "questions = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': '2018',\n",
       " 'Month': '12',\n",
       " 'Question': '\\n \\n1. Heeft het college kennisgenomen van de genoemde publicatie van het CIDI?  \\n \\n',\n",
       " 'Answer': ' \\nNee.  ',\n",
       " 'Document': 'https://amsterdam.raadsinformatie.nl/document/7170632/2/1382_19_Schriftelijke+vragen+Yimaz+indoctrinatie+via+lesmateriaal+van+CIDI',\n",
       " 'URLs': None,\n",
       " 'question_id': 'gY'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Questions with BM25+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, corpus, bm25, k, true_documents):\n",
    "    query_tokens = [token.lower() for token in str(query['Question']).lower().replace('\\n', '').split()]\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    results_heap = [(scores[i], doc['id'], doc['Textual_Content']) for i, doc in enumerate(corpus)]\n",
    "    results_heap.sort(reverse=True)\n",
    "    top_results = results_heap[:k]\n",
    "    \n",
    "    search_results = {\n",
    "        'question_id': query['question_id'],\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': [result[1] for result in top_results],\n",
    "        'ranked_text': [result[2] for result in top_results],\n",
    "        'true_passages': query['passages_ids'] if true_documents else [],\n",
    "        'scores': [result[0] for result in top_results],\n",
    "        'answer': query['Answer']\n",
    "    }\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_bm25_search(queries, corpus, k, true_documents=True):\n",
    "    tokenized_corpus = [[token.lower() for token in doc['Textual_Content'].lower().replace('\\n', '').split()] for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    search_results = [bm25_search(query, corpus, bm25, k=k, true_documents=true_documents) for query in queries]\n",
    "    return search_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0a4cb5cf69ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_bm25_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_bm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_for_ranking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassages_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 3:22 mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36mperform_bm25_search\u001b[0;34m(queries, corpus, k, true_documents)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_documents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_documents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36mbm25_search\u001b[0;34m(query, corpus, bm25, k, true_documents)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults_heap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresults_heap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_heap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults_heap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresults_heap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_heap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2360\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                     \u001b[0mpa_subtable_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                     formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2363\u001b[0m                         \u001b[0mpa_subtable_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mdecode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \"\"\"\n\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \"\"\"\n\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mzip_dict\u001b[0;34m(*dicts)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;34m\"\"\"Iterate over items of dictionaries grouped by their keys.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_bm25_all = perform_bm25_search(questions_for_ranking, passages_df, k=10, true_documents=False) # 3:22 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_bm25_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('passages_pickled.picle', 'wb') as f:\n",
    "    pickle.dump(passages_df, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
