{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to do exploratory analysis on the URLs which have been used as a reference in some of the answers from the MunicipalQA dataset.\n",
    "\n",
    "The following analysis has been performed:\n",
    "\n",
    "1. Most frequent URL domains\n",
    "2. Most frequent main paths of the corresponding domain\n",
    "3. Topics in the referenced URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ###\n",
    "import pandas as pd\n",
    "from yarl import URL\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.read_csv(open('/Users/natalipeeva/Desktop/Clean work/questions.csv', 'r'))\n",
    "urls = sum(map(lambda x: x.split('\\n'), questions[questions['URLs'].notnull()]['URLs']), [])\n",
    "urls = list(map(lambda x: x if x.startswith('http') else f'https://{x}', urls))\n",
    "len(urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make URLs from URL type - yarl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame()\n",
    "sample['url'] = urls\n",
    "sample['url'] = sample['url'].apply(lambda url: URL(url))\n",
    "sample['path'] =sample.url.apply(lambda url: url.path)\n",
    "sample['host'] =sample.url.apply(lambda url: url.host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common domains are:\n",
      "\n",
      "www.amsterdam.nl                       125\n",
      "www.rijksoverheid.nl                    60\n",
      "amsterdam.raadsinformatie.nl            48\n",
      "www.parool.nl                           22\n",
      "www.rivm.nl                             18\n",
      "www.at5.nl                              15\n",
      "www.ggd.amsterdam.nl                    13\n",
      "maps.amsterdam.nl                       10\n",
      "www.tweedekamer.nl                       8\n",
      "www.infomil.nl                           7\n",
      "www.nrc.nl                               7\n",
      "data.amsterdam.nl                        7\n",
      "www.telegraaf.nl                         7\n",
      "twitter.com                              7\n",
      "zoeken.amsterdam.raadsinformatie.nl      7\n",
      "www.cbs.nl                               6\n",
      "zoek.officielebekendmakingen.nl          6\n",
      "assets.amsterdam.nl                      6\n",
      "www.rvo.nl                               6\n",
      "www.werk.nl                              6\n",
      "Name: host, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The most common domains are:')\n",
    "print()\n",
    "print(sample['host'].value_counts().head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check URL (file) extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_count = 0\n",
    "non_html_count = 0\n",
    "\n",
    "extensions = []\n",
    "\n",
    "for url in urls:\n",
    "    # Extract the file extension from the URL\n",
    "    file_ext = os.path.splitext(url)[1]\n",
    "    extensions.append(file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 525), ('.', 108), ('.nl', 49), ('.pdf', 41), ('.html', 15)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(extensions).most_common(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some .pdf which should be accounted for during collection."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect amsterdam.nl paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_string(url, domain):\n",
    "    \"\"\"\n",
    "    Extracts the string between 'amsterdam.nl/' and the next '/' in a URL.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_index = url.find(domain + '/') + len(domain + '/')\n",
    "    end_index = url.find('/', start_index)\n",
    "    if end_index == -1:\n",
    "        end_index = len(url)\n",
    "    return url[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonen-leefomgeving', 12),\n",
       " ('bestuur-organisatie', 10),\n",
       " ('amsterdam.nl', 10),\n",
       " ('veelgevraagd', 8),\n",
       " ('publish', 7)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Amsterdam.nl ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.amsterdam.nl' in url:\n",
    "        paths.append(extract_string(url, 'amsterdam.nl'))\n",
    "\n",
    "Counter(paths).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('documenten', 41),\n",
       " ('onderwerpen', 10),\n",
       " ('actueel', 3),\n",
       " ('regering', 3),\n",
       " ('ministeries', 2),\n",
       " ('doe-mee', 1),\n",
       " ('le.com', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Rijksoverheid ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.rijksoverheid.nl' in url:\n",
    "        paths.append(extract_string(url, 'rijksoverheid.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('document', 46), ('cgi-bin', 7), ('vergadering', 1), ('modules', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### amsterdam.raadsinformatie.nl ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'amsterdam.raadsinformatie.nl' in url:\n",
    "        paths.append(extract_string(url, 'amsterdam.raadsinformatie.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amsterdam', 13),\n",
       " ('nieuws', 2),\n",
       " ('es-bb2825c9).', 1),\n",
       " ('nederland', 1),\n",
       " ('columns-opinie', 1),\n",
       " ('parool', 1),\n",
       " ('cs-b49e70edAfdeli', 1),\n",
       " ('opinie', 1),\n",
       " ('sport', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.parool.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.parool.nl' in url:\n",
    "        paths.append(extract_string(url, 'parool.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('publicaties', 5),\n",
       " ('windenergie', 3),\n",
       " ('coronavirus-covid-19', 2),\n",
       " ('documenten', 2),\n",
       " ('bibliotheek', 2),\n",
       " ('nieuws', 1),\n",
       " ('hitte', 1),\n",
       " ('sites', 1),\n",
       " ('monkeypox-apenpokken', 1),\n",
       " ('', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.rivm.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.rivm.nl' in url:\n",
    "        paths.append(extract_string(url, 'rivm.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gezond-wonen', 5),\n",
       " ('coronavirus', 2),\n",
       " ('publish', 1),\n",
       " ('beleid-onderzoek', 1),\n",
       " ('gezonde-en-kansrijke-start-amsterdam', 1),\n",
       " ('nieuwsoverzicht', 1),\n",
       " ('ggd', 1),\n",
       " ('infectieziekten', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.ggd.amsterdam.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.ggd.amsterdam.nl' in url:\n",
    "        paths.append(extract_string(url, 'ggd.amsterdam.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kamerstukken', 6), ('debat_en_vergadering', 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.tweedekamer.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.tweedekamer.nl' in url:\n",
    "        paths.append(extract_string(url, 'tweedekamer.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('onderwerpen', 7)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.infomil.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'www.infomil.nl' in url:\n",
    "        paths.append(extract_string(url, 'infomil.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artikelen', 4), ('publicaties', 3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### www.infomil.nl  ###########\n",
    "paths = []\n",
    "for url in urls:\n",
    "    if 'data.amsterdam.nl' in url:\n",
    "        paths.append(extract_string(url, 'data.amsterdam.nl'))\n",
    "\n",
    "Counter(paths).most_common()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be sure of the factual validity of our corpus we are going to collect supporting documents only from "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "1. The most frequently used domains as a reference are: amsterdam.nl, rijksoverheid.nl, rivm.nl, etc. \n",
    "2. The most frequent sub-domains were analyzed and would be taken into account during collection. \n",
    "\n",
    "\n",
    "\n",
    "**Additional findings after manual exploration**:\n",
    "\n",
    "1. Some URL paths are different at their current version than the version that has been used at the time of referencing \n",
    "2. Some URLs appear to be directing to a non-existent page\n",
    "3. A common error that results in a URL being broken is a wrong ending, which is either a \".\" or a \").\"\n",
    "\n",
    "# Actions to take\n",
    "1. Build a collection of supporting documents based on the most common domains and URL paths (url, html_content)\n",
    "2. Update the URLs of the references with their most current versions \n",
    "3. Clean the URLs if needed (e.g. if they end with a '.')\n",
    "4. Collect the HTML content of the refrence URLs as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
