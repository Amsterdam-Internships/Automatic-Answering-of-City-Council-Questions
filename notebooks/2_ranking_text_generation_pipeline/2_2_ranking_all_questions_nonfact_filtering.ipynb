{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions\n"
     ]
    }
   ],
   "source": [
    "%cd  /Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "src_dir = os.path.join(os.getcwd(), 'src_clean')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hashids import Hashids\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src_clean.preprocessing.passages import create_passages_dataframe, add_passages_ids\n",
    "from src_clean.preprocessing.text_preprocessing import preprocess_text\n",
    "from src_clean.ranking.sparse_ranking import perform_tfidf_search, perform_random_search, perform_bm25_search\n",
    "from src_clean.ranking.evaluation import calculate_average_metrics_retrieval, calculate_metrics_answer_similarity, simulate_answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('data/question_answer/questions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('data/question_answer/questions.csv')\n",
    "collection = pd.read_csv('data/amsterdam/amsterdam_full.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df = create_passages_dataframe(collection) # 50 secs for execution\n",
    "len(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean passages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates in general; drop duplictates in column 'Textual_Content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56850"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df = passages_df.drop_duplicates() # drop dup.\n",
    "len(passages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df = passages_df.drop_duplicates(subset='Textual_Content', keep=False) # drop dup. passages\n",
    "len(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process Passages Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_df['Preprocessed_Text'] = passages_df['Textual_Content'].apply(lambda x: preprocess_text(x,stem=True,\n",
    "                                                                                      remove_stopwords=True,\n",
    "                                                                                      lowercase_text=True,\n",
    "                                                                                      remove_punct=True)) # 40 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Passage ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "passages_df[\"id\"] = [hashids.encode(i) for i in range(len(passages_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Textual_Content</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60888</th>\n",
       "      <td>https://www.amsterdam.nl/nrga/</td>\n",
       "      <td>Transponeringstabel Transponeringstabel ( PDF ...</td>\n",
       "      <td>transponeringstabel transponeringstabel pdf kb...</td>\n",
       "      <td>RrLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60892</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>Postcode Toelichting Vul een geldige postcode ...</td>\n",
       "      <td>postcod toelicht vul geldig postcod volgend fo...</td>\n",
       "      <td>VyNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60893</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>Verleend Pieter Calandlaan 339 05 juni 2023 Be...</td>\n",
       "      <td>verleend pieter calandlan juni besluit eveneme...</td>\n",
       "      <td>Wz8x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60894</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>05 juni 2023 Besluit ( ) exploitatievergunning...</td>\n",
       "      <td>juni besluit exploitatievergunn horecabedrijf ...</td>\n",
       "      <td>XAMg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60895</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>juni 2023 Besluit apv vergunning Verleend - Ou...</td>\n",
       "      <td>juni besluit apv vergunn verleend oudezijd voo...</td>\n",
       "      <td>YBM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URL  \\\n",
       "60888                     https://www.amsterdam.nl/nrga/   \n",
       "60892  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "60893  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "60894  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "60895  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "\n",
       "                                         Textual_Content  \\\n",
       "60888  Transponeringstabel Transponeringstabel ( PDF ...   \n",
       "60892  Postcode Toelichting Vul een geldige postcode ...   \n",
       "60893  Verleend Pieter Calandlaan 339 05 juni 2023 Be...   \n",
       "60894  05 juni 2023 Besluit ( ) exploitatievergunning...   \n",
       "60895  juni 2023 Besluit apv vergunning Verleend - Ou...   \n",
       "\n",
       "                                       Preprocessed_Text    id  \n",
       "60888  transponeringstabel transponeringstabel pdf kb...  RrLE  \n",
       "60892  postcod toelicht vul geldig postcod volgend fo...  VyNX  \n",
       "60893  verleend pieter calandlan juni besluit eveneme...  Wz8x  \n",
       "60894  juni besluit exploitatievergunn horecabedrijf ...  XAMg  \n",
       "60895  juni besluit apv vergunn verleend oudezijd voo...  YBM2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.dropna(subset=['Question', 'Answer'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.drop_duplicates(subset='Answer', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.drop_duplicates(subset='Question', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n1. Heeft het college kennisgenomen van de...</td>\n",
       "      <td>\\nNee.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n2. Kan het college bevestigen of dit lesm...</td>\n",
       "      <td>\\nNee, het college heeft hier geen zicht op. ...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n                                         ...</td>\n",
       "      <td>\\nHet CIDI is duidelijk over de eigen doelste...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n4. Is het college bekend met de jaarlijks...</td>\n",
       "      <td>\\nHet college heeft hier kennis van genomen.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\na. Is het college van oordeel dat het CID...</td>\n",
       "      <td>vraag 4a: \\nHet college is voor een pluriform...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month                                           Question  \\\n",
       "0  2018    12  \\n \\n1. Heeft het college kennisgenomen van de...   \n",
       "1  2018    12  \\n \\n2. Kan het college bevestigen of dit lesm...   \n",
       "2  2018    12  \\n \\n                                         ...   \n",
       "3  2018    12  \\n \\n4. Is het college bekend met de jaarlijks...   \n",
       "4  2018    12  \\n \\na. Is het college van oordeel dat het CID...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0                                           \\nNee.     \n",
       "1   \\nNee, het college heeft hier geen zicht op. ...   \n",
       "2   \\nHet CIDI is duidelijk over de eigen doelste...   \n",
       "3      \\nHet college heeft hier kennis van genomen.    \n",
       "4   vraag 4a: \\nHet college is voor een pluriform...   \n",
       "\n",
       "                                            Document URLs  \n",
       "0  https://amsterdam.raadsinformatie.nl/document/...  NaN  \n",
       "1  https://amsterdam.raadsinformatie.nl/document/...  NaN  \n",
       "2  https://amsterdam.raadsinformatie.nl/document/...  NaN  \n",
       "3  https://amsterdam.raadsinformatie.nl/document/...  NaN  \n",
       "4  https://amsterdam.raadsinformatie.nl/document/...  NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['Preprocessed_Question'] = questions['Question'].apply(lambda x: preprocess_text(x,stem=True,\n",
    "                                                                                      remove_stopwords=True,\n",
    "                                                                                      lowercase_text=True,\n",
    "                                                                                      remove_punct=True)) \n",
    "\n",
    "questions['Preprocessed_Answer'] = questions['Answer'].apply(lambda x: preprocess_text(x,stem=True,\n",
    "                                                                                      remove_stopwords=True,\n",
    "                                                                                      lowercase_text=True,\n",
    "                                                                                      remove_punct=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.drop_duplicates(subset='Preprocessed_Question', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.drop_duplicates(subset='Preprocessed_Answer', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Preprocessed_Question</th>\n",
       "      <th>Preprocessed_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "      <td>617</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "      <td>2948</td>\n",
       "      <td>587</td>\n",
       "      <td>17374</td>\n",
       "      <td>17374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n1. Heeft het college kennisgenomen van de...</td>\n",
       "      <td>\\nNee.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>https://www.rijksoverheid.nl/documenten/kamers...</td>\n",
       "      <td>colleg kennisgenom genoemd publicatie cidi</td>\n",
       "      <td>nee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2620</td>\n",
       "      <td>1832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year  Month                                           Question  \\\n",
       "count   17374  17374                                              17374   \n",
       "unique     10     12                                              17374   \n",
       "top      2020      8  \\n \\n1. Heeft het college kennisgenomen van de...   \n",
       "freq     2620   1832                                                  1   \n",
       "\n",
       "           Answer                                           Document  \\\n",
       "count       17374                                              17374   \n",
       "unique      17374                                               2948   \n",
       "top      \\nNee.    https://amsterdam.raadsinformatie.nl/document/...   \n",
       "freq            1                                                 41   \n",
       "\n",
       "                                                     URLs  \\\n",
       "count                                                 617   \n",
       "unique                                                587   \n",
       "top     https://www.rijksoverheid.nl/documenten/kamers...   \n",
       "freq                                                    5   \n",
       "\n",
       "                             Preprocessed_Question Preprocessed_Answer  \n",
       "count                                        17374               17374  \n",
       "unique                                       17374               17374  \n",
       "top     colleg kennisgenom genoemd publicatie cidi                 nee  \n",
       "freq                                             1                   1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=questions[questions['Preprocessed_Answer'].str.split().str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_filter = ['bekend', 'kennisgenomen', 'op de hoogte', 'standpunt', 'mening', 'onbekend', 'vindt', 'visie',\n",
    "                   'herkent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions[~questions['Answer'].str.split().apply(lambda x: any(word.lower() in x for word in words_to_filter))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions[~questions['Question'].str.split().apply(lambda x: any(word.lower() in x for word in words_to_filter))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10971"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=questions[questions['Preprocessed_Answer'].str.split().str.len() < 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#questions.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add question ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "questions[\"question_id\"] = [hashids.encode(i) for i in range(len(questions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions.tail() # check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(questions)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "questions = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions[0] # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(passages_df)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "passages_df = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passages_df[1000] # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tfidf = perform_tfidf_search(questions, passages_df, k=100) # 6 mins for whole collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_search(query, collection, k, get_true_passages=False):\n",
    "    if get_true_passages:\n",
    "        true_documents = query['passages_ids']\n",
    "    else:\n",
    "        true_documents = []\n",
    "\n",
    "    # Randomly select k documents from the collection\n",
    "    collection_indices = np.arange(len(collection))\n",
    "    random_indices = np.random.choice(collection_indices, size=k, replace=False)\n",
    "    random_results = [collection[int(i)] for i in random_indices]\n",
    "\n",
    "    ranked_ids = [result['id'] for result in random_results]\n",
    "    ranked_text = [result['Textual_Content'] for result in random_results]\n",
    "    ranked_preprocessed = [result['Preprocessed_Text'] for result in random_results]\n",
    "    scores = []  # Assign random scores for demonstration purposes\n",
    "\n",
    "    # Dictionary with search results\n",
    "    search_results = {\n",
    "        'question_id': query['question_id'],\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text_preprocessed': ranked_preprocessed,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'scores': scores,\n",
    "        'answer': query['Answer'],\n",
    "        'preprocessed_question': query['Preprocessed_Question'],\n",
    "        'preprocessed_answer': query['Preprocessed_Answer']\n",
    "    }\n",
    "\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_search(queries, collection, k, get_true_passages= False):\n",
    "    \"\"\"\n",
    "    Perform random retrieval search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        collection: a pandas DataFrame representing the collection\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of dictionaries containing the search results\n",
    "    \"\"\"\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = random_search(query, collection, k=k, get_true_passages=get_true_passages)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random = perform_random_search(questions, passages_df, k=100) # 18 secs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save ranked results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_results(results, question_collection, passages_collection, folder_path):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Get the variable names of question_collection and passages_collection\n",
    "    question_var_name = [var_name for var_name, var_val in globals().items() if var_val is question_collection][0]\n",
    "    passages_var_name = [var_name for var_name, var_val in globals().items() if var_val is passages_collection][0]\n",
    "\n",
    "    # Save each result variable with its corresponding filename\n",
    "    for result in results:\n",
    "        # Get the variable name of the result variable\n",
    "        result_var_name = [var_name for var_name, var_val in globals().items() if var_val is result][0]\n",
    "        \n",
    "        # Generate the filename based on variable names\n",
    "        filename = '{}_{}_{}.pickle'.format(result_var_name, question_var_name, passages_var_name)\n",
    "        \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [results_tfidf, results_random]\n",
    "question_collection = questions\n",
    "passages_collection = passages_df\n",
    "folder_path = 'data/results_ranking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(results, question_collection, passages_collection, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/results_ranking/questions_preprocessed.pickle', 'wb') as f:\n",
    "    pickle.dump(questions, f)\n",
    "\n",
    "with open('data/results_ranking/passages_preprocessed.pickle', 'wb') as f:\n",
    "    pickle.dump(passages_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/data/results_ranking/results_tfidf_questions_passages_df.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
