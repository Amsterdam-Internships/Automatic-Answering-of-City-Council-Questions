{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "src_dir = os.path.join(os.getcwd(), 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from read_data.read_data import read_urls_questions, get_questions, get_url_content_tuples, get_relevant_docs\n",
    "from elasticsearch import Elasticsearch\n",
    "from retrieval.sparse_retrieval.bm25 import set_index, get_result_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected, questions =  read_urls_questions(os.path.join('data/reference_urls/reference_urls_collected.csv'),\n",
    "                                            os.path.join('data/question_answer/questions_updated_urls.csv'), clean_url_nan=True) # read collected urls and questions + remove unsuccessful collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam_only = questions[questions['Cleaned_URLs'].apply(lambda urls: any(url.startswith('https://www.amsterdam.nl') for url in urls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam_collected = pd.read_csv('data/collected/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8851"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amsterdam_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam_references = collected[collected['URL'].str.startswith('https://www.amsterdam.nl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam_missing = pd.DataFrame()  # Empty DataFrame to store missing rows\n",
    "missing_rows = []\n",
    "\n",
    "for index, row in amsterdam_references.iterrows():\n",
    "    if row['URL'] not in amsterdam_collected['URL'].tolist():\n",
    "        missing_rows.append(row.to_dict())\n",
    "\n",
    "amsterdam_missing = pd.DataFrame(missing_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amsterdam = pd.concat([amsterdam_collected, amsterdam_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8908"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_amsterdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = get_questions(amsterdam_only)\n",
    "document_list = get_url_content_tuples(all_amsterdam)\n",
    "mappings = {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = set_index(es_client=es_client, collected=all_amsterdam, mappings=mappings) # 48 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_result_tuples(es_client=es_client, questions=question_list, n=10) # 15 gives the best results ; when i set it to 5 gives 0,26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ba6036cb4dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "results[list(results.keys())[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.topk import recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for question in results.keys():\n",
    "    urls = []\n",
    "    for result in results[question][1]:\n",
    "        urls.append(result['url'])\n",
    "    predictions.append(list(set(urls)))\n",
    "\n",
    "relevant_docs = get_relevant_docs(amsterdam_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from irmetrics.topk import rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Reciprocal Rank: 0.044651011089367254\n"
     ]
    }
   ],
   "source": [
    "true = []\n",
    "for question in relevant_docs.keys():\n",
    "    true.append(list(set(relevant_docs[question])))\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = rr(true_values, predictions[i], k =7)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_mrr = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Mean Reciprocal Rank:\", average_mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.topk import recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Reciprocal Rank: 0.1232876712328767\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = recall(true_values, predictions[i], k=10)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_recall = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Mean Reciprocal Rank:\", average_recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources for Dutch tokenization\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe for the new data\n",
    "new_df = pd.DataFrame(columns=['URL', 'Textual_Content'])\n",
    "\n",
    "# Iterate over each row in the original dataframe\n",
    "for index, row in all_amsterdam.iterrows():\n",
    "    url = row['URL']\n",
    "    content = str(row['Textual_Content'])\n",
    "    \n",
    "    # Tokenize the content into words\n",
    "    words = word_tokenize(content, language='dutch')\n",
    "    \n",
    "    # Create passages of 100 words\n",
    "    passages = [' '.join(words[i:i+100]) for i in range(0, len(words), 100)]\n",
    "    \n",
    "    # Create a new dataframe for the passages\n",
    "    passage_df = pd.DataFrame({'URL': url, 'Textual_Content': passages})\n",
    "    \n",
    "    # Concatenate the new dataframe with the main dataframe\n",
    "    new_df = pd.concat([new_df, passage_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('data/amsterdam/amsterdam_passages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = get_url_content_tuples(new_df)\n",
    "mappings = {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = set_index(es_client=es_client, collected=new_df, mappings=mappings) # 7secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_result_tuples(es_client=es_client, questions=question_list, n=10) # 1:45 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Reciprocal Rank: 0.0319634703196347\n",
      "Average Recall: 0.0684931506849315\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for question in results.keys():\n",
    "    urls = []\n",
    "    for result in results[question][1]:\n",
    "        urls.append(result['url'])\n",
    "    predictions.append(list(set(urls)))\n",
    "\n",
    "relevant_docs = get_relevant_docs(amsterdam_only)\n",
    "\n",
    "true = []\n",
    "for question in relevant_docs.keys():\n",
    "    true.append(list(set(relevant_docs[question])))\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = rr(true_values, predictions[i], k =1000)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_mrr = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Mean Reciprocal Rank:\", average_mrr)\n",
    "\n",
    "\n",
    "from irmetrics.topk import recall\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = recall(true_values, predictions[i], k=10)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_recall = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Recall:\", average_recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsterdam_only.to_csv('data/amsterdam/only_amsterdam_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('data/amsterdam/bm25_documents_amsterdam.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amsterdam.to_csv('data/amsterdam/amsterdam_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('data/amsterdam/bm25_passages10_amsterdam.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more results: \n",
    "- if it's top 500: Average Recall: 0.3561643835616438; Average Mean Reciprocal Rank: 0.010190664748755714\n",
    "- If it's 200: 0,28\n",
    "- If 100: 0,21\n",
    "- 1000: Average Mean Reciprocal Rank: 0.008540249382361066; 0.3972602739726027\n",
    "- If 150: Average Mean Reciprocal Rank: 0.019564395660491188 ; Average Recall: 0.2671232876712329\n",
    "- If 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
