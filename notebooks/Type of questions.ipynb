{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('questions - questions-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_links = pd.read_csv('Questions_links_translations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_all['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = df_all['Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "        Tokenizes the input text.\n",
    "        Input: text - type(str)\n",
    "        Output: a list of tokens - type(list)\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text, language='dutch')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_token(token): # Doesn't work rn, should check how to do for Dutch\n",
    "    \"\"\"\n",
    "        Stems the given token using the PorterStemmer from the nltk library\n",
    "        Input: a single token\n",
    "        Output: the stem of the token\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, stop_words, stem=False, remove_stopwords=False, lowercase_text=False, remove_punct=False):\n",
    "    \"\"\"\n",
    "    Given a string, the function tokenizes\n",
    "    it and processes it according to the set requirements.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for token in tokenize(text):\n",
    "        if remove_stopwords and token.lower() in stop_words:\n",
    "            continue\n",
    "        if remove_punct and token.isdigit():\n",
    "            continue\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "        if stem:\n",
    "            token = stem_token(token)\n",
    "        if lowercase_text:\n",
    "            token = token.lower()\n",
    "        tokens.append(token)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(questions[0], stop, stem=False, remove_stopwords=True, lowercase_text=True, remove_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prepr = []\n",
    "questions_len = []\n",
    "for question in questions:\n",
    "    preprocessed = process_text(question, stop, remove_stopwords=True, lowercase_text=True, remove_punct=True)\n",
    "    questions_prepr.append(preprocessed)\n",
    "    questions_len.append(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=gensim.corpora.Dictionary(questions_prepr)\n",
    "bow_corpus = [dic.doc2bow(doc) for doc in questions_prepr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_q = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                   num_topics = 20,\n",
    "                                   id2word = dic,\n",
    "                                   passes = 10,\n",
    "                                   workers = 2, \n",
    "                                        random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_q.show_topics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=20\n",
    "nb_columns = 5\n",
    "nb_rows = math.ceil(K / nb_columns)\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()] \n",
    "cols = cols * math.ceil(K / len(cols))\n",
    "\n",
    "cloud = WordCloud(background_color='white',\n",
    "                  width=400,\n",
    "                  height=400,\n",
    "                  max_words=10,\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model_q.show_topics(num_topics=K, num_words=10, formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=nb_columns, nrows=nb_rows, \n",
    "                         figsize=(4*nb_columns, 4*nb_rows), \n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i, (topic, ax) in enumerate(zip(topics, axes.flatten())):\n",
    "    topic_words = dict(topic[1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    ax.imshow(cloud)\n",
    "    #ax.set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_prepr = []\n",
    "answers_len = []\n",
    "for answer in answers:\n",
    "    preprocessed = process_text(str(answer), stop, remove_stopwords=True, lowercase_text=True, remove_punct=True)\n",
    "    answers_prepr.append(preprocessed)\n",
    "    answers_len.append(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=gensim.corpora.Dictionary(answers_prepr)\n",
    "bow_corpus = [dic.doc2bow(doc) for doc in answers_prepr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                   num_topics = 30,\n",
    "                                   id2word = dic,\n",
    "                                   passes = 10,\n",
    "                                   workers = 2, \n",
    "                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=30\n",
    "nb_columns = 5\n",
    "nb_rows = math.ceil(K / nb_columns)\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "cols = cols * math.ceil(K / len(cols))\n",
    "\n",
    "cloud = WordCloud(background_color='white',\n",
    "                  width=400,\n",
    "                  height=400,\n",
    "                  max_words=10,\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(num_topics=K, num_words=10, formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=nb_columns, nrows=nb_rows, \n",
    "                         figsize=(4*nb_columns, 4*nb_rows), \n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i, (topic, ax) in enumerate(zip(topics, axes.flatten())):\n",
    "    topic_words = dict(topic[1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    ax.imshow(cloud)\n",
    "    ax.set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types = {'wie': 0,\n",
    "                 'wat': 0,\n",
    "                 'waar': 0,\n",
    "                 'waneer': 0,\n",
    "                 'waarom': 0,\n",
    "                 'welke': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions_prepr:\n",
    "    for w in q:\n",
    "        if w in question_types:\n",
    "            question_types[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a reason why 'wie' and 'wat'are stopwords? Is wie like in German?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_words = {'mening': 0,\n",
    "                 'convictie': 0, \n",
    "                 'denkbeeld': 0,\n",
    "                 'denkwijs': 0,\n",
    "                 'denkwijze': 0,\n",
    "                 'dunk':0,\n",
    "                 'gedacht':0,\n",
    "                 'gedachte':0,\n",
    "                 'geest': 0,\n",
    "                 'gevoelen':0,\n",
    "                 'gezindheid': 0,\n",
    "                 'idee': 0,\n",
    "                 'inzicht':0,\n",
    "                 'inzien':0,\n",
    "                 'kijk':0, \n",
    "                 'oordeel':0,\n",
    "                 'opinie':0,\n",
    "                 'bevindingen':0,\n",
    "                 'besluiten':0,\n",
    "                 'beslissend':0,\n",
    "                 'stellingname':0,\n",
    "                 'visie':0,\n",
    "                 'zienswijze':0,\n",
    "                 'zin':0,\n",
    "                'bekend':0,\n",
    "                'college':0,\n",
    "                'vindt':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions_prepr:\n",
    "    for w in q:\n",
    "        if w in opinion_words:\n",
    "            opinion_words[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_words = {'mening': 0,\n",
    "                 'convictie': 0, \n",
    "                 'denkbeeld': 0,\n",
    "                 'denkwijs': 0,\n",
    "                 'denkwijze': 0,\n",
    "                 'dunk':0,\n",
    "                 'gedacht':0,\n",
    "                 'gedachte':0,\n",
    "                 'geest': 0,\n",
    "                 'gevoelen':0,\n",
    "                 'gezindheid': 0,\n",
    "                 'idee': 0,\n",
    "                 'inzicht':0,\n",
    "                 'inzien':0,\n",
    "                 'kijk':0, \n",
    "                 'oordeel':0,\n",
    "                 'opinie':0,\n",
    "                 'bevindingen':0,\n",
    "                 'besluiten':0,\n",
    "                 'beslissend':0,\n",
    "                 'stellingname':0,\n",
    "                 'visie':0,\n",
    "                 'zienswijze':0,\n",
    "                 'zin':0,\n",
    "                'bekend':0,\n",
    "                'college':0,\n",
    "                'vindt':0}\n",
    "for q in questions_prepr:\n",
    "    for w in opinion_words:\n",
    "        if w in q: \n",
    "            opinion_words[w]+=1\n",
    "opinion_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_words_links = {'mening': 0,\n",
    "                 'convictie': 0, \n",
    "                 'denkbeeld': 0,\n",
    "                 'denkwijs': 0,\n",
    "                 'denkwijze': 0,\n",
    "                 'dunk':0,\n",
    "                 'gedacht':0,\n",
    "                 'gedachte':0,\n",
    "                 'geest': 0,\n",
    "                 'gevoelen':0,\n",
    "                 'gezindheid': 0,\n",
    "                 'idee': 0,\n",
    "                 'inzicht':0,\n",
    "                 'inzien':0,\n",
    "                 'kijk':0, \n",
    "                 'oordeel':0,\n",
    "                 'opinie':0,\n",
    "                 'bevindingen':0,\n",
    "                 'besluiten':0,\n",
    "                 'beslissend':0,\n",
    "                 'stellingname':0,\n",
    "                 'visie':0,\n",
    "                 'zienswijze':0,\n",
    "                 'zin':0,\n",
    "                'bekend':0,\n",
    "                'college':0,\n",
    "                'vindt':0,\n",
    "                'standpunt':0,\n",
    "                'bereid':0,\n",
    "                'kennisgenomen':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prepr_stop_url = []\n",
    "for question in df_trans_links['Question']:\n",
    "    preprocessed = process_text(question, stop, remove_stopwords=False, lowercase_text=True)\n",
    "    questions_prepr_stop_url.append(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions_prepr_stop_url:\n",
    "    for w in q:\n",
    "        if w in opinion_words:\n",
    "            opinion_words_links[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_words_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prepr_stop = []\n",
    "for question in questions:\n",
    "    preprocessed = process_text(question, stop, remove_stopwords=False, lowercase_text=True, remove_punct=True)\n",
    "    questions_prepr_stop.append(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx])\n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_q = sum(questions_prepr_stop, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_trigrams=get_top_ngram(corpus_q,3)\n",
    "x,y=map(list,zip(*top_n_trigrams[:10])) \n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_trigrams=get_top_ngram(corpus_q,3)\n",
    "top_n_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_bigrams=get_top_ngram(corpus_q,2)\n",
    "x,y=map(list,zip(*top_n_bigrams)) \n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_bigrams=get_top_ngram(corpus_q,2)\n",
    "top_n_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types_stop = {'wie': 0,\n",
    "                 'wat': 0,\n",
    "                 'waar': 0,\n",
    "                 'waneer': 0,\n",
    "                 'waarom': 0,\n",
    "                 'welke': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions_prepr_stop:\n",
    "    for w in q:\n",
    "        if w in question_types_stop:\n",
    "            question_types[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_start = []\n",
    "for q in questions_prepr_stop:\n",
    "    q_start.append(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted = Counter(q_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=map(list,zip(*counted.most_common(25))) \n",
    "sns.barplot(x=y,y=x, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_start_2 = []\n",
    "for q in questions_prepr_stop:\n",
    "    q_start_2.append(q[2])\n",
    "counted2 = Counter(q_start_2)\n",
    "counted2.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
