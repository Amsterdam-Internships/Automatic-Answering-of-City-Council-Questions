{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comments to install required packages\n",
    "#! pip install nltk==3.5\n",
    "#! pip install pandas==2.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the notebook directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Get the root directory by navigating upwards two levels\n",
    "root_dir = os.path.dirname(os.path.abspath(os.path.join(notebook_dir, '../../')))\n",
    "\n",
    "# Change the current working directory to the root directory\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/question_answer/questions.csv'\n",
    "df_all = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ngarms_beginning(sentence, n):\n",
    "    tokens = nltk.word_tokenize(str(sentence))\n",
    "\n",
    "    ngrams = list(nltk.ngrams(tokens, n))\n",
    "\n",
    "    beginning_ngrams = []\n",
    "    for gram in ngrams:\n",
    "        if gram[0][0].isupper():\n",
    "            beginning_ngrams.append(gram)\n",
    "\n",
    "    return beginning_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_all['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = df_all['Answer']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common n-grams Questions and Answers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_lengths = [3, 4, 5, 6, 7]\n",
    "\n",
    "a_ngrams = [[] for _ in range(len(ngrams_lengths))]\n",
    "q_ngrams = [[] for _ in range(len(ngrams_lengths))]\n",
    "\n",
    "a_3grams, a_4grams, a_5grams, a_6grams, a_7grams = a_ngrams\n",
    "q_3grams, q_4grams, q_5grams, q_6grams, q_7grams = q_ngrams\n",
    "\n",
    "for a, q in zip(answers, questions):\n",
    "    for i, n in enumerate(ngrams_lengths):\n",
    "        a_ngrams[i].append(detect_ngarms_beginning(str(a), n))\n",
    "        q_ngrams[i].append(detect_ngarms_beginning(q, n))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_lengths = [0, 1, 2, 3, 4]  # Index mapping to n-gram lengths\n",
    "ngrams_range = range(3, 8)  # Actual n-gram lengths\n",
    "top_n = 12\n",
    "\n",
    "for i, n in zip(ngrams_lengths, ngrams_range):\n",
    "    single_list = [item for sublist in q_ngrams[i] for item in sublist]\n",
    "    freq_dist = nltk.FreqDist(single_list)\n",
    "    top_ngrams = freq_dist.most_common(top_n)\n",
    "    print(f\"Top {top_n} {n}-grams:\")\n",
    "    for ngram, frequency in top_ngrams:\n",
    "        print(f\"{ngram}: {frequency}\")\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_lengths = [0, 1, 2, 3, 4]  # Index mapping to n-gram lengths\n",
    "ngrams_range = range(3, 8)  # Actual n-gram lengths\n",
    "top_n = 12\n",
    "\n",
    "for i, n in zip(ngrams_lengths, ngrams_range):\n",
    "    single_list = [item for sublist in a_ngrams[i] for item in sublist]\n",
    "    freq_dist = nltk.FreqDist(single_list)\n",
    "    top_ngrams = freq_dist.most_common(top_n)\n",
    "    print(f\"Top {top_n} {n}-grams:\")\n",
    "    for ngram, frequency in top_ngrams:\n",
    "        print(f\"{ngram}: {frequency}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
