{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "src_dir = os.path.join(os.getcwd(), 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from read_data.read_data import read_urls_questions, get_questions, get_url_content_tuples, get_relevant_docs\n",
    "from elasticsearch import Elasticsearch\n",
    "from retrieval.sparse_retrieval.bm25 import set_index, get_result_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'c913d73a452f',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': '2OYk7KTMQx6zkjPCEjNf2Q',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected, questions =  read_urls_questions('data/all_references/reference_urls_collected_clean_pdf.csv',\n",
    "                                            'data/all_references/questions_updated_urls.csv', clean_url_nan=True) # read collected urls and questions + remove unsuccessful collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "print(len(collected))\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = get_questions(questions)\n",
    "document_list = get_url_content_tuples(collected)\n",
    "mappings = {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = set_index(es_client=es_client, collected=collected, mappings=mappings) # 7secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_result_tuples(es_client=es_client, questions=question_list, n=5) # 1:45 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.topk import recall\n",
    "predictions = []\n",
    "for question in results.keys():\n",
    "    urls = []\n",
    "    for result in results[question][1]:\n",
    "        urls.append(result['url'])\n",
    "    predictions.append(list(set(urls)))\n",
    "\n",
    "\n",
    "relevant_docs = get_relevant_docs(questions)\n",
    "\n",
    "true = []\n",
    "for question in relevant_docs.keys():\n",
    "    true.append(list(set(relevant_docs[question])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Reciprocal Rank: 0.13560775540641312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from irmetrics.topk import rr\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = rr(true_values, predictions[i], k =5)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_mrr = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Mean Reciprocal Rank:\", average_mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Reciprocal Rank: 0.22408650260999252\n"
     ]
    }
   ],
   "source": [
    "from irmetrics.topk import recall\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank for each question\n",
    "mrr_values = []\n",
    "for i in range(len(predictions)):\n",
    "    true_values = true[i]\n",
    "    mrr = recall(true_values, predictions[i], k=5)\n",
    "    mrr_values.append(mrr)\n",
    "\n",
    "# Calculate the average Mean Reciprocal Rank\n",
    "average_recall = np.mean(mrr_values)\n",
    "\n",
    "print(\"Average Mean Reciprocal Rank:\", average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('data/results/bm25_results_all_ref.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.to_csv('data/question_answer/all_ref_questions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
