{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions\n"
     ]
    }
   ],
   "source": [
    "%cd  /Users/natalipeeva/Documents/GitHub/Automatic-Answering-of-City-Council-Questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "from hashids import Hashids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking = pd.read_csv('data/question_answer/amsterdam_questions.csv')\n",
    "collection = pd.read_csv('data/amsterdam/amsterdam_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_unformatted = list(questions_for_ranking['URLs'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all URLs appearing in the references in the answers are in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_list = []\n",
    "for string in urls_unformatted:\n",
    "    sublist = ast.literal_eval(string)\n",
    "    reference_list.append(sublist)\n",
    "\n",
    "reference_urls = []\n",
    "for sublist in reference_list:\n",
    "    reference_urls.extend(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reference_urls) # There are in total 84 urls refrencing to amsterdam.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_urls = list(collection['URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "elements_not_in_collected = []\n",
    "for element in reference_urls:\n",
    "    if element in collected_urls:\n",
    "        count += 1\n",
    "    else:\n",
    "        elements_not_in_collected.append(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ggd.amsterdam.nl/gezond-wonen/zwemmen-open-water/',\n",
       " 'https://www.rivm.nl/publicaties/health-effects-related-to-wind-turbine-sound-update',\n",
       " 'http://www.amsterdam.nl/stadslandbouw',\n",
       " 'https://www.amsterdam.nl/nieuws/nieuwsoverzicht/dak-en-thuislozen']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_not_in_collected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data to Paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passages function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_passages_dataframe(collection):\n",
    "    all_passages_df = pd.DataFrame(columns=['URL', 'Textual_Content'])\n",
    "\n",
    "    for index, row in collection.iterrows():\n",
    "        url = row['URL']\n",
    "        content = str(row['Textual_Content'])\n",
    "\n",
    "        sentences = nltk.sent_tokenize(content, language='dutch')\n",
    "\n",
    "        passages = []\n",
    "        passage_words = []\n",
    "        word_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_words = nltk.word_tokenize(sentence, language='dutch')\n",
    "\n",
    "            while len(sentence_words) > 0:\n",
    "                if word_count + len(sentence_words) <= 100:\n",
    "                    passage_words.extend(sentence_words)\n",
    "                    word_count += len(sentence_words)\n",
    "                    sentence_words = []\n",
    "                else:\n",
    "                    remaining_words = 100 - word_count\n",
    "                    passage_words.extend(sentence_words[:remaining_words])\n",
    "                    passages.append(' '.join(passage_words))\n",
    "                    passage_words = []\n",
    "                    word_count = 0\n",
    "                    sentence_words = sentence_words[remaining_words:]\n",
    "\n",
    "        if passage_words:\n",
    "            passages.append(' '.join(passage_words))\n",
    "\n",
    "        passage_df = pd.DataFrame({'URL': url, 'Textual_Content': passages})\n",
    "        all_passages_df = pd.concat([all_passages_df, passage_df], ignore_index=True)\n",
    "\n",
    "    return all_passages_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60902"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df = create_passages_dataframe(collection) # 50 secs for execution\n",
    "len(passages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_df['Textual_Content'] = passages_df['Textual_Content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_df = passages_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "src_dir = os.path.join(os.getcwd(), 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from read_data.read_data import read_urls_questions, get_questions, get_url_content_tuples, get_relevant_docs\n",
    "from elasticsearch import Elasticsearch\n",
    "from retrieval.sparse_retrieval.bm25 import set_index, get_result_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('data/question_answer/questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19134"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n \\n1. Heeft het college kennisgenomen van de...\n",
       "1        \\n \\n2. Kan het college bevestigen of dit lesm...\n",
       "2        \\n \\n                                         ...\n",
       "3        \\n \\n4. Is het college bekend met de jaarlijks...\n",
       "4        \\n \\na. Is het college van oordeel dat het CID...\n",
       "                               ...                        \n",
       "19129    \\n \\n8. Welke mogelijkheden ziet het college o...\n",
       "19130    \\n \\n  \\n1. Kan het college wat meer inzicht g...\n",
       "19131    \\n \\n2. Hoeveel van de meldingen hebben betrek...\n",
       "19132    \\n \\n3. Zijn er overlastmeldingen of regelover...\n",
       "19133    \\n \\n4. Kan het college het hierboven genoemde...\n",
       "Name: Question, Length: 18748, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['Question'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = get_questions(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19134"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercased_questions = [str(question).lower() for question in question_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = set_index(es_client=es_client, collected=passages_df, mappings=mappings) # 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_result_tuples(es_client=es_client, questions=lowercased_questions, n=10) # 8 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. is het college bereid om te investeren in de signalerende functies van huisartsen en wijkteams \\nop het punt van huiselijk geweld? zo ja, op welke wijze? \\n \\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results.keys())[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_bm25_elastic.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add passage ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "passages_df[\"id\"] = [hashids.encode(i) for i in range(len(passages_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Textual_Content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60897</th>\n",
       "      <td>https://www.amsterdam.nl/nieuws/kennisgevingen...</td>\n",
       "      <td>evenementen . Lijst Over deze site Privacy Coo...</td>\n",
       "      <td>r1vk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60898</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>Hulp voor dak- of thuislozen - Gemeente Amster...</td>\n",
       "      <td>v1zg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60899</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>Op zoek naar ( tijdelijke ) woonruimte Opvang ...</td>\n",
       "      <td>w1Am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60900</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>onverzekerden Collectieve zorgverzekering Amst...</td>\n",
       "      <td>g0GZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60901</th>\n",
       "      <td>https://www.amsterdam.nl/zorg-ondersteuning/on...</td>\n",
       "      <td>tot inspraakavonden . Wat organiseert de gemee...</td>\n",
       "      <td>j1kY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URL  \\\n",
       "60897  https://www.amsterdam.nl/nieuws/kennisgevingen...   \n",
       "60898  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60899  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60900  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "60901  https://www.amsterdam.nl/zorg-ondersteuning/on...   \n",
       "\n",
       "                                         Textual_Content    id  \n",
       "60897  evenementen . Lijst Over deze site Privacy Coo...  r1vk  \n",
       "60898  Hulp voor dak- of thuislozen - Gemeente Amster...  v1zg  \n",
       "60899  Op zoek naar ( tijdelijke ) woonruimte Opvang ...  w1Am  \n",
       "60900  onverzekerden Collectieve zorgverzekering Amst...  g0GZ  \n",
       "60901  tot inspraakavonden . Wat organiseert de gemee...  j1kY  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add paragraphs ids to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_passages_ids(questions_for_ranking, passages_df):\n",
    "    matching_ids_column = []\n",
    "    for index, row in questions_for_ranking.iterrows():\n",
    "        matching_ids = []\n",
    "        for url in ast.literal_eval(row['URLs']):\n",
    "            for index2, row2 in passages_df.iterrows():\n",
    "                if url == row2['URL']:\n",
    "                    matching_ids.append(row2['id'])\n",
    "        if matching_ids:\n",
    "            matching_ids_column.append(matching_ids)\n",
    "        else:\n",
    "            matching_ids_column.append(None)\n",
    "    questions_for_ranking['passages_ids'] = matching_ids_column\n",
    "    return questions_for_ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking = add_passages_ids(questions_for_ranking, passages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Cleaned_URLs</th>\n",
       "      <th>passages_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>\\n7.\\nKan het college de reeds bestaande zwemp...</td>\n",
       "      <td>\\nVoor het vinden van de officiële zwemplekken...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?casei...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?casei...</td>\n",
       "      <td>[y8RV, zm0r, AnyB, Bgzx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n3. Huisartsen geven aan meer informatie n...</td>\n",
       "      <td>\\nDe uitvoerder van de regeling, het CAK, lij...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n8. Weten ongedocumenteerden de weg naar m...</td>\n",
       "      <td>\\nDe Kruispost wordt goed bezocht, maar het c...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>\\n \\n4. Is het college tot nu toe tevreden met...</td>\n",
       "      <td>\\nJa, met de beschikbare middelen is de uitvo...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/wonen-leefomgeving/...</td>\n",
       "      <td>['https://www.amsterdam.nl/wonen-leefomgeving/...</td>\n",
       "      <td>[zkqm, Ap8P, Bq1N, Dvwq, EwK0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>\\n \\n1. \\nKan aan de werkinstructie worden toe...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/privacy/loket/']</td>\n",
       "      <td>['https://www.amsterdam.nl/privacy/loket/']</td>\n",
       "      <td>[G0w8, JBEP, KDAY, LEAA]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  Year  Month  \\\n",
       "0             1           1  2020      6   \n",
       "1             6           7  2021      8   \n",
       "2             7           8  2021      8   \n",
       "3             9          14  2022      7   \n",
       "4            10          16  2019     10   \n",
       "\n",
       "                                            Question  \\\n",
       "0  \\n7.\\nKan het college de reeds bestaande zwemp...   \n",
       "1  \\n \\n3. Huisartsen geven aan meer informatie n...   \n",
       "2  \\n \\n8. Weten ongedocumenteerden de weg naar m...   \n",
       "3  \\n \\n4. Is het college tot nu toe tevreden met...   \n",
       "4  \\n \\n1. \\nKan aan de werkinstructie worden toe...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  \\nVoor het vinden van de officiële zwemplekken...   \n",
       "1   \\nDe uitvoerder van de regeling, het CAK, lij...   \n",
       "2   \\nDe Kruispost wordt goed bezocht, maar het c...   \n",
       "3   \\nJa, met de beschikbare middelen is de uitvo...   \n",
       "4                                                ...   \n",
       "\n",
       "                                            Document  \\\n",
       "0  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "1  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "2  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "3  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "4  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "\n",
       "                                                URLs  \\\n",
       "0  ['https://www.amsterdam.nl/veelgevraagd/?casei...   \n",
       "1  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "2  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "3  ['https://www.amsterdam.nl/wonen-leefomgeving/...   \n",
       "4        ['https://www.amsterdam.nl/privacy/loket/']   \n",
       "\n",
       "                                        Cleaned_URLs  \\\n",
       "0  ['https://www.amsterdam.nl/veelgevraagd/?casei...   \n",
       "1  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "2  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "3  ['https://www.amsterdam.nl/wonen-leefomgeving/...   \n",
       "4        ['https://www.amsterdam.nl/privacy/loket/']   \n",
       "\n",
       "                                        passages_ids  \n",
       "0                           [y8RV, zm0r, AnyB, Bgzx]  \n",
       "1  [nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...  \n",
       "2  [nVkY, o9lA, p6mX, qXnD, rNoB, v7vL, w8wg, xNx...  \n",
       "3                     [zkqm, Ap8P, Bq1N, Dvwq, EwK0]  \n",
       "4                           [G0w8, JBEP, KDAY, LEAA]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add question ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "questions_for_ranking[\"question_id\"] = [hashids.encode(i) for i in range(len(questions_for_ranking))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Cleaned_URLs</th>\n",
       "      <th>passages_ids</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>124</td>\n",
       "      <td>178</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>\\n \\n2. Hoe evalueert het college het function...</td>\n",
       "      <td>\\nOp  22 september 2009 stemde het toenmalige...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?produ...</td>\n",
       "      <td>['https://www.amsterdam.nl/veelgevraagd/?produ...</td>\n",
       "      <td>[wjXR, g5A6, j2E5, k5GX, lOJ6, mwK0, nZLl, oYM...</td>\n",
       "      <td>Nk6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>127</td>\n",
       "      <td>181</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>\\n3. Is het college bereid om te investeren in...</td>\n",
       "      <td>\\nHet college investeert al in de signalerend...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/sociaaldomein/zorgp...</td>\n",
       "      <td>['https://www.amsterdam.nl/sociaaldomein/zorgp...</td>\n",
       "      <td>[0KpG, g0Kl, j1Mz, k1KY, l1LJ, m56A, n1XD]</td>\n",
       "      <td>OYp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>128</td>\n",
       "      <td>182</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>\\n \\n2. Deelt het college de mening dat het ee...</td>\n",
       "      <td>\\nNee, het college deelt deze mening van de P...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/nrga/']</td>\n",
       "      <td>['https://www.amsterdam.nl/nrga/']</td>\n",
       "      <td>[o1KN, p1Kr, q1XR, r1Nk, v17g, w18m, xgNn, yjO...</td>\n",
       "      <td>PNw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>129</td>\n",
       "      <td>183</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n \\n \\n6.  Recent heeft de burgemeester aange...</td>\n",
       "      <td>\\na) Het verlenen van een vergunning is een b...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/nieuws/kennisgeving...</td>\n",
       "      <td>['https://www.amsterdam.nl/nieuws/kennisgeving...</td>\n",
       "      <td>[j1Vz, k1VY, l1VJ, m5VA, n1VD, o19N, p16r, q1r...</td>\n",
       "      <td>QWl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>134</td>\n",
       "      <td>193</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n \\n12. Welke informatievoorziening is er van...</td>\n",
       "      <td>\\nZorgaanbieders zijn verantwoordelijk voor h...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>['https://www.amsterdam.nl/zorg-ondersteuning/...</td>\n",
       "      <td>[n1GE, o1A3, p19N, q1AG, v1zg, w1Am, g0GZ, j1kY]</td>\n",
       "      <td>R6q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  Year  Month  \\\n",
       "68           124         178  2014      8   \n",
       "69           127         181  2022      5   \n",
       "70           128         182  2017      5   \n",
       "71           129         183  2020      2   \n",
       "72           134         193  2020      3   \n",
       "\n",
       "                                             Question  \\\n",
       "68  \\n \\n2. Hoe evalueert het college het function...   \n",
       "69  \\n3. Is het college bereid om te investeren in...   \n",
       "70  \\n \\n2. Deelt het college de mening dat het ee...   \n",
       "71  \\n \\n \\n6.  Recent heeft de burgemeester aange...   \n",
       "72  \\n \\n12. Welke informatievoorziening is er van...   \n",
       "\n",
       "                                               Answer  \\\n",
       "68   \\nOp  22 september 2009 stemde het toenmalige...   \n",
       "69   \\nHet college investeert al in de signalerend...   \n",
       "70   \\nNee, het college deelt deze mening van de P...   \n",
       "71   \\na) Het verlenen van een vergunning is een b...   \n",
       "72   \\nZorgaanbieders zijn verantwoordelijk voor h...   \n",
       "\n",
       "                                             Document  \\\n",
       "68  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "69  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "70  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "71  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "72  https://amsterdam.raadsinformatie.nl/document/...   \n",
       "\n",
       "                                                 URLs  \\\n",
       "68  ['https://www.amsterdam.nl/veelgevraagd/?produ...   \n",
       "69  ['https://www.amsterdam.nl/sociaaldomein/zorgp...   \n",
       "70                 ['https://www.amsterdam.nl/nrga/']   \n",
       "71  ['https://www.amsterdam.nl/nieuws/kennisgeving...   \n",
       "72  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "\n",
       "                                         Cleaned_URLs  \\\n",
       "68  ['https://www.amsterdam.nl/veelgevraagd/?produ...   \n",
       "69  ['https://www.amsterdam.nl/sociaaldomein/zorgp...   \n",
       "70                 ['https://www.amsterdam.nl/nrga/']   \n",
       "71  ['https://www.amsterdam.nl/nieuws/kennisgeving...   \n",
       "72  ['https://www.amsterdam.nl/zorg-ondersteuning/...   \n",
       "\n",
       "                                         passages_ids question_id  \n",
       "68  [wjXR, g5A6, j2E5, k5GX, lOJ6, mwK0, nZLl, oYM...         Nk6  \n",
       "69         [0KpG, g0Kl, j1Mz, k1KY, l1LJ, m56A, n1XD]         OYp  \n",
       "70  [o1KN, p1Kr, q1XR, r1Nk, v17g, w18m, xgNn, yjO...         PNw  \n",
       "71  [j1Vz, k1VY, l1VJ, m5VA, n1VD, o19N, p16r, q1r...         QWl  \n",
       "72   [n1GE, o1A3, p19N, q1AG, v1zg, w1Am, g0GZ, j1kY]         R6q  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_ranking.drop('Cleaned_URLs', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(questions_for_ranking)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "questions_for_ranking = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2020,\n",
       " 'Month': 6,\n",
       " 'Question': '\\n7.\\nKan het college de reeds bestaande zwemplekken in Amsterdam en de directe \\nomgeving, die zich op fietsafstand bevinden, beter communiceren zodat mensen \\nweten waar ze allemaal heen kunnen op de fiets om te zwemmen?\\n',\n",
       " 'Answer': '\\nVoor het vinden van de officiële zwemplekken is er informatie op de site \\nhttps://www.zwemwater.nl/.Hier is ook informatie te vinden over veilig zwemmen en gezondheidsrisico’s en het \\nCorona protocol zwemmen en recreëren in en aan oppervlaktewater.\\nOp de kaart met zwemwater, stadsstranden en fonteinen geeft de gemeente \\nAmsterdam een overzicht van zwemplekken in open water: \\nhttps://maps.amsterdam.nl/zwemwater/ . \\nZie tevens de site: https://www.amsterdam.nl/veelgevraagd/?caseid=%7BD6E280FB-\\n4A76-40A0-9B88-12B87E446FA6%7D\\nVoorts is het voor de gezondheidsrisico’s goed kennis te nemen van de site van de \\nGGD over het zwemmen in open water: https://www.ggd.amsterdam.nl/gezond-\\nwonen/zwemmen-open-water/ ',\n",
       " 'Document': 'https://amsterdam.raadsinformatie.nl/document/8824200/5/888',\n",
       " 'URLs': \"['https://www.amsterdam.nl/veelgevraagd/?caseid=%7BD6E280FB-4A76-40A0-9B88-12B87E446FA6%7D', 'https://www.ggd.amsterdam.nl/gezond-wonen/zwemmen-open-water/']\",\n",
       " 'passages_ids': ['y8RV', 'zm0r', 'AnyB', 'Bgzx'],\n",
       " 'question_id': 'gY'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_for_ranking[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(passages_df)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "passages_df = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URL': 'https://www.amsterdam.nl/veelgevraagd/meer-veel-gezochte-vragen/?view=top&categoryid=%7B11ADEA27-898E-482C-97D4-48CFCEFE550C%7D',\n",
       " 'Textual_Content': 'Wat mag er in de broodcontainer ? Wat mag er bij het blad- en snoeiafval ? Deel deze pagina Deel deze pagina op Facebook Deel deze pagina op Twitter Deel deze pagina op LinkedIn Deel deze pagina op WhatsApp Print deze pagina Gemeente Amsterdam Contact Hebt u een vraag en kunt u het antwoord niet vinden op deze website ? Neem dan contact met ons op . Contactformulier Bel het telefoonnummer 14 020maandag tot en met vrijdag van 08.00 tot 18.00 uur Contactgegevens en openingstijden Volg de gemeente Nieuwsbrief Amsterdam Twitter Facebook Instagram LinkedIn YouTube Werkenbij Kalender Van buurtactiviteiten tot',\n",
       " 'id': 'gN3'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(passages_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Amsterdam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_search(query, vectorizer, matrix, collection, k):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using tf-idf.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        vectorizer: a fitted TfidfVectorizer\n",
    "        matrix: the document-term matrix obtained from the fitted vectorizer\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of (document_id, score, document_content), sorted in descending relevance to the given query\n",
    "    \"\"\"\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = str(query['Question']).lower().replace('\\n', '')\n",
    "\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "\n",
    "    query_vector = vectorizer.transform([preprocessed_query])\n",
    "    question_id = query['question_id']\n",
    "\n",
    "    cosine_similarities = matrix.dot(query_vector.T).toarray().flatten()\n",
    "\n",
    "    results_heap = []  # heap for efficiency to maintain the top-k results\n",
    "\n",
    "    # iterate over the collection and update the heap with the top-k results\n",
    "    for i, doc in enumerate(collection):\n",
    "        doc_id = doc['id']\n",
    "        score = cosine_similarities[i]\n",
    "        document_content = doc['Textual_Content']\n",
    "        heapq.heappush(results_heap, (score, doc_id, document_content))\n",
    "        if len(results_heap) > k:\n",
    "            heapq.heappop(results_heap)\n",
    "\n",
    "    results_heap.sort(reverse=True)  # sort descending\n",
    "    top_results = results_heap[:k]\n",
    "\n",
    "    cosine_scores = [result[0] for result in top_results]\n",
    "    ranked_ids = [result[1] for result in top_results]\n",
    "    ranked_text = [result[2] for result in top_results]\n",
    "\n",
    "    # Create a dictionary containing the search results\n",
    "    search_results = {\n",
    "        'question_id': question_id,\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'cosine_scores': cosine_scores, \n",
    "        'answer': query['Answer']\n",
    "    }\n",
    "\n",
    "    return search_results  # return top k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tfidf_search(queries, collection, k):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a dictionary where the key is the query and the value is a list of (document_id, score, document_content) tuples\n",
    "    \"\"\"\n",
    "    # Extract document contents from the collection\n",
    "    document_contents = [str(doc['Textual_Content']).lower().replace('\\n', '') for doc in collection]\n",
    "\n",
    "    # Initialize and fit the TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(document_contents)\n",
    "\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = tfidf_search(query, vectorizer, matrix, collection, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = perform_tfidf_search(questions_for_ranking, passages_df, k=100) # 2:18 mins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.topk import recall, ap, ndcg, precision, rr, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irmetrics.relevance import relevant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant_counts(relevant[:, np.newaxis], ranked[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics(results, k):\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "    rr_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    for result in results:\n",
    "        ranked = result['ranked_ids']\n",
    "        relevant = result['true_passages']\n",
    "\n",
    "        recall_k = recall(relevant, ranked, k)\n",
    "        ndcg_k = calculate_ndcg(relevant, ranked, k)\n",
    "        rr_k = rr(relevant, ranked, k)\n",
    "        precision_k = precision(relevant, ranked, k)\n",
    "\n",
    "        recall_scores.append(recall_k)\n",
    "        ndcg_scores.append(ndcg_k)\n",
    "        rr_scores.append(rr_k)\n",
    "        precision_scores.append(precision_k)\n",
    "\n",
    "    average_recall = sum(recall_scores) / len(recall_scores)\n",
    "    average_ndcg = sum(ndcg_scores) / len(ndcg_scores)\n",
    "    average_rr = sum(rr_scores) / len(rr_scores)\n",
    "    average_precision = sum(precision_scores) / len(precision_scores)\n",
    "\n",
    "    average_metrics = {\n",
    "        'average_recall@{}'.format(k): average_recall,\n",
    "        'average_ndcg@{}'.format(k): average_ndcg,\n",
    "        'average_rr@{}'.format(k): average_rr,\n",
    "        'average_precision@{}'.format(k): average_precision\n",
    "    }\n",
    "\n",
    "    return average_metrics\n",
    "\n",
    "\n",
    "def calculate_ndcg(relevant, ranked, k):\n",
    "    warnings.filterwarnings('ignore', 'invalid value encountered', RuntimeWarning)\n",
    "    ndcg_k = ndcg(relevant, ranked, k)\n",
    "    if np.isnan(ndcg_k) or np.isinf(ndcg_k):\n",
    "        ndcg_k = 0.0\n",
    "    return ndcg_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0274\n",
      "average_ndcg@5: 0.0539\n",
      "average_rr@5: 0.0422\n",
      "average_precision@5: 0.0274\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0192\n",
      "average_ndcg@10: 0.0577\n",
      "average_rr@10: 0.0491\n",
      "average_precision@10: 0.0164\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0758\n",
      "average_ndcg@100: 0.1008\n",
      "average_rr@100: 0.0585\n",
      "average_precision@100: 0.0078\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_tfidf.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_search(query, collection, k):\n",
    "    \"\"\"\n",
    "    Perform random retrieval from the collection.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        collection: a list of tuples (document_id, document_content)\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a dictionary containing the search results\n",
    "    \"\"\"\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "\n",
    "    # Randomly select k documents from the collection\n",
    "    random_results = random.sample(collection.to_list(), k)\n",
    "\n",
    "    ranked_ids = [result['id'] for result in random_results]\n",
    "    ranked_text = [result['Textual_Content'] for result in random_results]\n",
    "    cosine_scores = []  # Assign random scores for demonstration purposes\n",
    "\n",
    "    # Create a dictionary containing the search results\n",
    "    search_results = {\n",
    "        'question_id': query['question_id'],\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'cosine_scores': cosine_scores,\n",
    "        'answer': query['Answer'],\n",
    "    }\n",
    "\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_random_search(queries, collection, k):\n",
    "    \"\"\"\n",
    "    Perform random retrieval search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        collection: a pandas DataFrame representing the collection\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of dictionaries containing the search results\n",
    "    \"\"\"\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = random_search(query, collection, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random = perform_random_search(questions_for_ranking, passages_df, k=100) # 18 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0000\n",
      "average_ndcg@5: 0.0000\n",
      "average_rr@5: 0.0000\n",
      "average_precision@5: 0.0000\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0000\n",
      "average_ndcg@10: 0.0000\n",
      "average_rr@10: 0.0000\n",
      "average_precision@10: 0.0000\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0000\n",
      "average_ndcg@100: 0.0000\n",
      "average_rr@100: 0.0000\n",
      "average_precision@100: 0.0000\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results_random, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from rank_bm25 import BM25L\n",
    "from rank_bm25 import BM25Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, corpus, bm25, k):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using BM25 ranking.\n",
    "    Input:\n",
    "        query - an (unprocessed) query\n",
    "        collection: a list of document contents\n",
    "        bm25: initialized BM25Okapi object\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of (document_id, score, document_content), sorted in descending relevance to the given query\n",
    "    \"\"\"\n",
    "    # Preprocess the query\n",
    "    preprocessed_query = str(query['Question']).lower().replace('\\n', '')\n",
    "    query_tokens = preprocessed_query.split()\n",
    "\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    results_heap = []\n",
    "\n",
    "    # Iterate over the corpus and update the heap with the top-k results\n",
    "    for i, doc in enumerate(corpus):\n",
    "        doc_id = doc['id']\n",
    "        score = scores[i]\n",
    "        document_content = doc['Textual_Content']\n",
    "        heapq.heappush(results_heap, (score, doc_id, document_content))\n",
    "        if len(results_heap) > k:\n",
    "            heapq.heappop(results_heap)\n",
    "\n",
    "    results_heap.sort(reverse=True)  # Sort descending\n",
    "    top_results = results_heap[:k]\n",
    "\n",
    "    bm25_scores = [result[0] for result in top_results]\n",
    "    ranked_ids = [result[1] for result in top_results]\n",
    "    ranked_text = [result[2] for result in top_results]\n",
    "\n",
    "    # Create a dictionary containing the search results\n",
    "\n",
    "    query_text = query['Question']\n",
    "    true_documents = query['passages_ids']\n",
    "    question_id = query['question_id']\n",
    "\n",
    "    search_results = {\n",
    "    'question_id': question_id,\n",
    "    'question': query_text,\n",
    "    'ranked_ids': ranked_ids,\n",
    "    'ranked_text': ranked_text,\n",
    "    'true_passages': true_documents,\n",
    "    'scores': bm25_scores, \n",
    "    'answer': query['Answer']\n",
    "    }\n",
    "\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_bm25_search(queries, corpus, k):\n",
    "    \"\"\"\n",
    "    Perform BM25 search for each query in a list of queries.\n",
    "    Input:\n",
    "        queries - a list of queries\n",
    "        corpus: a list of document contents\n",
    "        k: the number of top search results to retrieve\n",
    "    Output: a list of dictionaries, where each dictionary contains the search results for a query\n",
    "    \"\"\"\n",
    "    # Preprocess the corpus\n",
    "    tokenized_corpus = [doc['Textual_Content'].lower().replace('\\n', '').split() for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    search_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = bm25_search(query, corpus, bm25, k=k)\n",
    "        search_results.append(results)\n",
    "\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bm25 = perform_bm25_search(questions_for_ranking, passages_df, k=100) # 3:22 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n \\n8. Weten ongedocumenteerden de weg naar medische instellingen zoals Kruispost wel te \\nvinden? In hoeverre kunnen religieuze en maatschappelijke partners zoals informele \\nvoedselvoorzieningen een rol spelen om de bekendheid hiervan verder te vergroten?  \\n \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bm25[2]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for p in passages_df:\n",
    "    counter.append(len(p['Textual_Content'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(counter)\n",
    "max_indices = [index for index, value in enumerate(counter) if value == max_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URL': 'https://www.amsterdam.nl/veelgevraagd/?productid=%7B10FA65AD-1A1D-4F5E-9555-AD8E4D83AFE2%7D#case_%7B9DB81075-8649-4C03-9BB3-87E13157EAAB%7D',\n",
       " 'Textual_Content': 'gehandicaptenparkeerkaart ( GPK ) kunnen een parkeervergunning voor gehandicapte bezoekers aanvragen . Hiermee parkeert u gratis in gebieden waar betaald parkeren geldt . Gratis parkeren Waar geldig Welke parkeerkaart ? Extra informatie Alle parkeerplaatsen op straat waar betaald parkeren geldt in Amsterdam Parkeervergunning voor gehandicapte bezoekers op vast kenteken of met wisselend kenteken Parkeerparkeervergunning voor gehandicapte bezoekers is digitaal , u hoeft niets in de auto te leggen . Bij een parkeervergunning voor gehandicapte bezoekers met een wisselend kenteken moet u zich elke dag aanmelden . Alle straten in Weesp waar betaald parkeren geldt , inclusief het P & R-terrein',\n",
       " 'id': 'gnk3'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df[12000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for k=5:\n",
      "average_recall@5: 0.0027\n",
      "average_ndcg@5: 0.0086\n",
      "average_rr@5: 0.0068\n",
      "average_precision@5: 0.0027\n",
      "\n",
      "Metrics for k=10:\n",
      "average_recall@10: 0.0027\n",
      "average_ndcg@10: 0.0083\n",
      "average_rr@10: 0.0068\n",
      "average_precision@10: 0.0027\n",
      "\n",
      "Metrics for k=100:\n",
      "average_recall@100: 0.0211\n",
      "average_ndcg@100: 0.0347\n",
      "average_rr@100: 0.0106\n",
      "average_precision@100: 0.0029\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 100]\n",
    "# for document 0 the results are quite high\n",
    "for k in ks:\n",
    "    print('\\nMetrics for k={}:'.format(k))\n",
    "    average_metrics = calculate_average_metrics(results_bm25, k)\n",
    "    for metric, value in average_metrics.items():\n",
    "        print('{}: {:.4f}'.format(metric, value)) #BM25 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_bm25.pickle', 'wb') as f:\n",
    "    pickle.dump(results_bm25, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results_ranking/amsterdam_100words_ranked_random.pickle', 'wb') as f:\n",
    "    pickle.dump(results_random, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/natalipeeva/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the language to Dutch\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_len = []\n",
    "for q in questions_for_ranking:\n",
    "    ans_len.append(len(word_tokenize(q['Answer'], language='dutch')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.8767123287671"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ans_len)/len(ans_len) # 256.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(generated_summaries, reference_summaries):\n",
    "    # Convert non-string elements to strings\n",
    "    generated_summaries = [str(summary) for summary in generated_summaries]\n",
    "    reference_summaries = [str(summary) for summary in reference_summaries]\n",
    "\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    rouge_scores = []\n",
    "    for generated_summary, reference_summary in zip(generated_summaries, reference_summaries):\n",
    "        scores = scorer.score(generated_summary, reference_summary)\n",
    "        rouge_scores.append(scores)\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_score = corpus_bleu([[ref.split()] for ref in reference_summaries], [gen.split() for gen in generated_summaries], smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(reference_summaries, generated_summaries, average='micro')  # Adjust 'average' parameter as needed\n",
    "\n",
    "\n",
    "    # Access the scores as needed\n",
    "    metrics = {\n",
    "        \"ROUGE-1 (Average)\": sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"ROUGE-2 (Average)\": sum([score['rouge2'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"ROUGE-L (Average)\": sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
    "        \"BLEU Score\": bleu_score,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_answer(list_passages):\n",
    "    concatenated_string = \"\"  # Initialize the concatenated string\n",
    "    for paragraph in list_passages:\n",
    "        tokens = word_tokenize(paragraph)\n",
    "        if len(word_tokenize(concatenated_string)) + len(tokens) <= 256:\n",
    "            concatenated_string += \" \" + paragraph\n",
    "        else:\n",
    "            break  # Stop concatenating if the token count exceeds 256\n",
    "    return concatenated_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers = []\n",
    "for key in results.keys():\n",
    "    concatenated_string = \"\"  # Initialize the concatenated string\n",
    "    for paragraph in results[key][1]:\n",
    "        tokens = word_tokenize(paragraph['text'])\n",
    "        if len(word_tokenize(concatenated_string)) + len(tokens) <= 256:\n",
    "            concatenated_string += \" \" + paragraph['text']\n",
    "        else:\n",
    "            break  # Stop concatenating if the token count exceeds 256\n",
    "    simulated_answers.append(concatenated_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18748"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simulated_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for index, row in questions.iterrows():\n",
    "    question = str(row['Question']).lower()  # Convert the question to lowercase\n",
    "    for key in results.keys():\n",
    "        if str(key) == str(question):\n",
    "            answer = str(row['Answer']).lower()  # Convert the answer to lowercase\n",
    "            answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19134"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = list(questions['Answer'])\n",
    "lowercased_answers = [str(answer).lower() for answer in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19134"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lowercased_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The number of hypotheses and their reference(s) should be the same ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-120562f24df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulated_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercased_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-98ec1faa1299>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(generated_summaries, reference_summaries)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Compute BLEU score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreference_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSmoothingFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Compute F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mhyp_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     assert len(list_of_references) == len(hypotheses), (\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;34m\"The number of hypotheses and their reference(s) should be the \"\u001b[0m \u001b[0;34m\"same \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The number of hypotheses and their reference(s) should be the same "
     ]
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers, lowercased_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers = []\n",
    "for result in results:\n",
    "    simulated_answers.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5865262ae210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions_for_ranking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for question in questions_for_ranking:\n",
    "    answers.append(question['Answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.2313289582763451,\n",
       " 'ROUGE-2 (Average)': 0.0344184919464686,\n",
       " 'ROUGE-L (Average)': 0.12278253414413527,\n",
       " 'BLEU Score': 0.007980492756711336,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers_random = []\n",
    "for result in results_random:\n",
    "    simulated_answers_random.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.19952015091584155,\n",
       " 'ROUGE-2 (Average)': 0.02156878779122388,\n",
       " 'ROUGE-L (Average)': 0.1092907814352237,\n",
       " 'BLEU Score': 0.0032005437617806634,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers_random, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_answers_bm25 = []\n",
    "for result in results_bm25:\n",
    "    simulated_answers_bm25.append(simulate_answer(result['ranked_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1 (Average)': 0.2538702529604056,\n",
       " 'ROUGE-2 (Average)': 0.03811834858547292,\n",
       " 'ROUGE-L (Average)': 0.1352721216338226,\n",
       " 'BLEU Score': 0.00818301351999974,\n",
       " 'F1 Score': 0.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(simulated_answers_bm25, answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking all with best ranker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get BM25 for all questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('data/question_answer/questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashids = Hashids()\n",
    "questions[\"question_id\"] = [hashids.encode(i) for i in range(len(questions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Document</th>\n",
       "      <th>URLs</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n1. Heeft het college kennisgenomen van de...</td>\n",
       "      <td>\\nNee.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n2. Kan het college bevestigen of dit lesm...</td>\n",
       "      <td>\\nNee, het college heeft hier geen zicht op. ...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n                                         ...</td>\n",
       "      <td>\\nHet CIDI is duidelijk over de eigen doelste...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\n4. Is het college bekend met de jaarlijks...</td>\n",
       "      <td>\\nHet college heeft hier kennis van genomen.</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n \\na. Is het college van oordeel dat het CID...</td>\n",
       "      <td>vraag 4a: \\nHet college is voor een pluriform...</td>\n",
       "      <td>https://amsterdam.raadsinformatie.nl/document/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month                                           Question  \\\n",
       "0  2018    12  \\n \\n1. Heeft het college kennisgenomen van de...   \n",
       "1  2018    12  \\n \\n2. Kan het college bevestigen of dit lesm...   \n",
       "2  2018    12  \\n \\n                                         ...   \n",
       "3  2018    12  \\n \\n4. Is het college bekend met de jaarlijks...   \n",
       "4  2018    12  \\n \\na. Is het college van oordeel dat het CID...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0                                           \\nNee.     \n",
       "1   \\nNee, het college heeft hier geen zicht op. ...   \n",
       "2   \\nHet CIDI is duidelijk over de eigen doelste...   \n",
       "3      \\nHet college heeft hier kennis van genomen.    \n",
       "4   vraag 4a: \\nHet college is voor een pluriform...   \n",
       "\n",
       "                                            Document URLs question_id  \n",
       "0  https://amsterdam.raadsinformatie.nl/document/...  NaN          gY  \n",
       "1  https://amsterdam.raadsinformatie.nl/document/...  NaN          jR  \n",
       "2  https://amsterdam.raadsinformatie.nl/document/...  NaN          k5  \n",
       "3  https://amsterdam.raadsinformatie.nl/document/...  NaN          l5  \n",
       "4  https://amsterdam.raadsinformatie.nl/document/...  NaN          mO  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_table = pa.Table.from_pandas(questions)\n",
    "arrow_dict = arrow_table.to_pydict()\n",
    "questions = Dataset.from_dict(arrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': '2018',\n",
       " 'Month': '12',\n",
       " 'Question': '\\n \\n1. Heeft het college kennisgenomen van de genoemde publicatie van het CIDI?  \\n \\n',\n",
       " 'Answer': ' \\nNee.  ',\n",
       " 'Document': 'https://amsterdam.raadsinformatie.nl/document/7170632/2/1382_19_Schriftelijke+vragen+Yimaz+indoctrinatie+via+lesmateriaal+van+CIDI',\n",
       " 'URLs': None,\n",
       " 'question_id': 'gY'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Questions with BM25+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, corpus, bm25, k, true_documents):\n",
    "    query_tokens = [token.lower() for token in str(query['Question']).lower().replace('\\n', '').split()]\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    results_heap = [(scores[i], doc['id'], doc['Textual_Content']) for i, doc in enumerate(corpus)]\n",
    "    results_heap.sort(reverse=True)\n",
    "    top_results = results_heap[:k]\n",
    "    \n",
    "    search_results = {\n",
    "        'question_id': query['question_id'],\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': [result[1] for result in top_results],\n",
    "        'ranked_text': [result[2] for result in top_results],\n",
    "        'true_passages': query['passages_ids'] if true_documents else [],\n",
    "        'scores': [result[0] for result in top_results],\n",
    "        'answer': query['Answer']\n",
    "    }\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "\n",
    "def perform_bm25_search(queries, corpus, k, true_documents=True):\n",
    "    tokenized_corpus = [[token.lower() for token in doc['Textual_Content'].lower().replace('\\n', '').split()] for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    search_results = [bm25_search(query, corpus, bm25, k=k, true_documents=true_documents) for query in queries]\n",
    "    return search_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0a4cb5cf69ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_bm25_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_bm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_for_ranking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassages_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 3:22 mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36mperform_bm25_search\u001b[0;34m(queries, corpus, k, true_documents)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_documents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbm25_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_documents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36mbm25_search\u001b[0;34m(query, corpus, bm25, k, true_documents)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults_heap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresults_heap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_heap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-2efc683785c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults_heap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Textual_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresults_heap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_heap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2360\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                     \u001b[0mpa_subtable_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                     formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2363\u001b[0m                         \u001b[0mpa_subtable_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mdecode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \"\"\"\n\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \"\"\"\n\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mzip_dict\u001b[0;34m(*dicts)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;34m\"\"\"Iterate over items of dictionaries grouped by their keys.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_bm25_all = perform_bm25_search(questions_for_ranking, passages_df, k=10, true_documents=False) # 3:22 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_bm25_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('passages_pickled.picle', 'wb') as f:\n",
    "    pickle.dump(passages_df, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "src_dir = os.path.join(os.getcwd(), 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from read_data.read_data import read_urls_questions, get_questions, get_url_content_tuples, get_relevant_docs\n",
    "from elasticsearch import Elasticsearch\n",
    "from retrieval.sparse_retrieval.bm25 import set_index, get_result_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "        \"properties\": {\n",
    "            \"url\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"},\n",
    "            \"p_id\": {\"type\": \"text\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_index(mappings, es_client, collected):\n",
    "    es_client.indices.delete(index=\"qa_attempt1\", ignore=[400, 404])\n",
    "    es_client.indices.create(index=\"qa_attempt1\", mappings=mappings)\n",
    "\n",
    "    for i, row in enumerate(collected):\n",
    "        doc = {\n",
    "            \"url\": row[\"URL\"],\n",
    "            \"text\": str(row[\"Textual_Content\"]),\n",
    "            \"p_id\": row['id']\n",
    "        }\n",
    "                \n",
    "        es_client.index(index=\"qa_attempt1\", id=i, document=doc)\n",
    "\n",
    "    return es_client\n",
    "\n",
    "\n",
    "\n",
    "def query_es_index(question, es_client, index_name=\"qa_attempt1\", n_results=10, min_length=0):\n",
    "    \"\"\"\n",
    "    Perform a search query on an Elasticsearch index based on a provided question.\n",
    "    \"\"\"\n",
    "    q = str(question).lower()\n",
    "    banned = [] #[\"how\", \"why\", \"what\", \"where\", \"which\", \"do\", \"does\", \"is\", \"?\", \"eli5\", \"eli5:\"]\n",
    "    #q = \" \".join([w for w in q.split() if w not in banned])\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": q,\n",
    "                    \"fields\": [\"url\", \"text\"],\n",
    "                    \"type\": \"cross_fields\",\n",
    "                }\n",
    "            },\n",
    "            \"size\": 2 * n_results,\n",
    "        },\n",
    "    )\n",
    "    hits = response[\"hits\"][\"hits\"]\n",
    "    support_doc = \"<P> \" + hits[0][\"_source\"][\"text\"] if hits else \"\"\n",
    "    res_list = [\n",
    "        {\n",
    "            \"passage_id\": hit[\"_source\"][\"p_id\"],\n",
    "            \"score\": hit[\"_score\"],\n",
    "            \"passage_text\": hit[\"_source\"][\"text\"],\n",
    "            \"url\": hit[\"_source\"][\"url\"]\n",
    "        }\n",
    "        for hit in hits\n",
    "    ]\n",
    "    res_list = [\n",
    "        res\n",
    "        for res in res_list\n",
    "        if len(res[\"passage_text\"].split()) > min_length\n",
    "    ][:n_results]\n",
    "    return support_doc, res_list\n",
    "\n",
    "def get_result_tuples(es_client, questions, index_name='qa_attempt1', n=10):\n",
    "\n",
    "    results = []  # To store the results for all questions\n",
    "\n",
    "    for question in questions:\n",
    "        support_doc, res_list = query_es_index(question['Question'], es_client, index_name=index_name, n_results=n)\n",
    "        results.append({\n",
    "            'question': question['Question'],\n",
    "            'question_id': question['question_id'],\n",
    "            'ranked_ids': [res['passage_id'] for res in res_list],\n",
    "            'true_passages': question['passages_ids'],\n",
    "            'scores': [res['score'] for res in res_list],\n",
    "            'answer': question['Answer']\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Replace the Elasticsearch host and port with your own\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"url\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"p_id\": {\n",
    "            \"type\": \"text\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-2cdab27ee3bc>:2: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=\"qa_attempt1\", ignore=[400, 404])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-1c2c7a4672a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mes_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmappings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassages_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-2cdab27ee3bc>\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(mappings, es_client, collected)\u001b[0m\n\u001b[1;32m     10\u001b[0m         }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mes_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qa_attempt1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mes_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py\u001b[0m in \u001b[0;36mindex\u001b[0;34m(self, index, document, id, error_trace, filter_path, human, if_primary_term, if_seq_no, op_type, pipeline, pretty, refresh, require_alias, routing, timeout, version, version_type, wait_for_active_shards)\u001b[0m\n\u001b[1;32m   2314\u001b[0m         \u001b[0m__body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0m__headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accept\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2316\u001b[0;31m         return self.perform_request(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m   2317\u001b[0m             \u001b[0m__method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         meta, resp_body = self.transport.perform_request(\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elastic_transport/_transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 meta, raw_data = node.perform_request(\n\u001b[0m\u001b[1;32m    330\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elastic_transport/_node/_http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mbody_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             response = self.pool.urlopen(  # type: ignore[no-untyped-call]\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es_client = set_index(mappings, es_client, passages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-2cdab27ee3bc>:25: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es_client.search(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-00342d6001e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_elastic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions_for_ranking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-2cdab27ee3bc>\u001b[0m in \u001b[0;36mget_result_tuples\u001b[0;34m(es_client, questions, index_name, n)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0msupport_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_es_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         results.append({\n\u001b[1;32m     63\u001b[0m             \u001b[0;34m'question'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-2cdab27ee3bc>\u001b[0m in \u001b[0;36mquery_es_index\u001b[0;34m(question, es_client, index_name, n_results, min_length)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#[\"how\", \"why\", \"what\", \"where\", \"which\", \"do\", \"does\", \"is\", \"?\", \"eli5\", \"eli5:\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#q = \" \".join([w for w in q.split() if w not in banned])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     response = es_client.search(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         body={\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[0m\n\u001b[1;32m   3855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m             \u001b[0m__headers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3857\u001b[0;31m         return self.perform_request(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m   3858\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3859\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         meta, resp_body = self.transport.perform_request(\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elastic_transport/_transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 meta, raw_data = node.perform_request(\n\u001b[0m\u001b[1;32m    330\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/elastic_transport/_node/_http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mbody_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             response = self.pool.urlopen(  # type: ignore[no-untyped-call]\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_elastic = get_result_tuples(es_client, questions_for_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_elastic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-4e1af095d54f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_elastic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_elastic' is not defined"
     ]
    }
   ],
   "source": [
    "results_elastic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['URL', 'Textual_Content', 'id'],\n",
       "    num_rows: 60902\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = {\n",
    "        'question_id': question_id,\n",
    "        'question': query['Question'],\n",
    "        'ranked_ids': ranked_ids,\n",
    "        'ranked_text': ranked_text,\n",
    "        'true_passages': true_documents,\n",
    "        'cosine_scores': cosine_scores, \n",
    "        'answer': query['Answer']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_result_tuples(es_client=es_client, questions=question_list, n=5) # 15 gives the best results ; when i set it to 5 gives 0,26"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea4c3bcc219a1292b0d1d9543a9b9f82ed18a35340190a3cbd50b3110bbb4e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
